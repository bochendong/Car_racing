{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from PIL import Image\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import namedtuple\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "import torch.optim as optim\n",
    "from torch.distributions import Beta\n",
    "from torch.utils.data.sampler import BatchSampler, SubsetRandomSampler\n",
    "\n",
    "from torch.autograd import Function\n",
    "\n",
    "import gnwrapper\n",
    "import gym\n",
    "from gym import logger as gymlogger\n",
    "gymlogger.set_level(30)\n",
    "\n",
    "from IPython.display import HTML\n",
    "from IPython import display as ipythondisplay\n",
    "from pyvirtualdisplay import Display\n",
    "import wandb\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import car_racing as cr\n",
    "\n",
    "import os\n",
    "import glob\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "print(device)\n",
    "\n",
    "if (os.path.exists(\"./output_r\")) == False:\n",
    "    os.mkdir(\"output_r\")\n",
    "    \n",
    "for epoch in range (3000):\n",
    "    files = glob.glob(\"./output_r/*.png\")\n",
    "\n",
    "    for f in files:\n",
    "        os.remove(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReverseLayerF(Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, x, alpha):\n",
    "        ctx.alpha = alpha\n",
    "        return x.view_as(x)\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        output = grad_output.neg() * ctx.alpha\n",
    "        return output, None  \n",
    "\n",
    "class DSN(nn.Module):\n",
    "    def __init__(self, num_out = 2):\n",
    "        super(DSN, self).__init__()\n",
    "        \n",
    "        \n",
    "        self.sketch = nn.Sequential(\n",
    "            nn.Conv3d(4, 4, kernel_size=(1, 1, 3), stride=1),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.source_encoder = nn.Sequential(\n",
    "            nn.Conv2d(4, 8, kernel_size=4, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(8, 16, kernel_size=3, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 32, kernel_size=3, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=2),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        self.target_encoder = nn.Sequential(\n",
    "            nn.Conv2d(4, 8, kernel_size=4, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(8, 16, kernel_size=3, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 32, kernel_size=3, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=2),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        self.shared_encoder = nn.Sequential(\n",
    "            nn.Conv2d(4, 8, kernel_size=4, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(8, 16, kernel_size=3, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 32, kernel_size=3, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 48, kernel_size=3, stride=2),\n",
    "            nn.ReLU(),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tensor = torch.rand(64, 4, 96, 96, 3)\n",
    "\n",
    "dsn = DSN()\n",
    "\n",
    "sketch = dsn.sketch(test_tensor)\n",
    "sketch = torch.squeeze(sketch)\n",
    "print(sketch.size())\n",
    "\n",
    "source_encode = dsn.source_encoder(sketch)\n",
    "print(source_encode.size())\n",
    "\n",
    "target_encode = dsn.target_encoder(sketch)\n",
    "print(target_encode.size())\n",
    "\n",
    "share_encode = dsn.shared_encoder(sketch)\n",
    "print(share_encode.size())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
