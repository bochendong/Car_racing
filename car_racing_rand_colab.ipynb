{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hpANlTAssfdF"
      },
      "source": [
        "# Colab env settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UfHgya4Jsdas",
        "outputId": "2ed68d9a-934f-449d-a269-d4a3f6b39be1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'car_racing' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/bochendong/car_racing.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "yX7L7IlDnyvU"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!sudo apt update && sudo apt install python-opengl\n",
        "!sudo apt update && sudo apt install xvfb\n",
        "!pip install gym-notebook-wrapper stable-baselines[mpi] box2d box2d-kengz pyvirtualdisplay pyglet\n",
        "!pip install wandb\n",
        "!pip install gym==0.21.0\n",
        "!pip install pyvirtualdisplay -qq\n",
        "!pip install folium==0.2.1\n",
        "!apt-get install -y xvfb python-opengl ffmpeg -qq"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install box2d"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n4GnViajtd1B",
        "outputId": "9055f091-a552-4cd4-efa7-ecd704d9131a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: box2d in /usr/local/lib/python3.7/dist-packages (2.3.10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "zUgm5ewmnyvV"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import random\n",
        "\n",
        "from PIL import Image\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import namedtuple\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as T\n",
        "import torch.optim as optim\n",
        "from torch.distributions import Beta\n",
        "from torch.utils.data.sampler import BatchSampler, SubsetRandomSampler\n",
        "\n",
        "from torch.autograd import Function\n",
        "\n",
        "import gnwrapper\n",
        "import gym\n",
        "from gym import logger as gymlogger\n",
        "gymlogger.set_level(30)\n",
        "\n",
        "from IPython.display import HTML\n",
        "from IPython import display as ipythondisplay\n",
        "from pyvirtualdisplay import Display\n",
        "import wandb\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import glob"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd car_racing"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NGrLEYQbtqWv",
        "outputId": "93705a86-eb29-410f-d02c-1ddcfde55ba2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/car_racing\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import car_racing as cr\n",
        "\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "print(device)\n",
        "\n",
        "if (os.path.exists(\"./output_r\")) == False:\n",
        "    os.mkdir(\"output_r\")\n",
        "    \n",
        "for epoch in range (3000):\n",
        "    files = glob.glob(\"./output_r/*.png\")\n",
        "\n",
        "    for f in files:\n",
        "        os.remove(f)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qmqqcZfbtj63",
        "outputId": "139d07c4-c471-4987-e735-8111bf7576a3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nu12ch3KssCE"
      },
      "source": [
        "# Car_racing Enviorment settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "0bSmOb2d6qPq"
      },
      "outputs": [],
      "source": [
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HBhiAnYKnyvZ",
        "outputId": "a9349fae-875e-439f-92e2-2cc8f9f582b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gym/spaces/box.py:74: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
            "  \"Box bound precision lowered by casting to {}\".format(self.dtype)\n",
            "/usr/local/lib/python3.7/dist-packages/gym/spaces/box.py:74: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
            "  \"Box bound precision lowered by casting to {}\".format(self.dtype)\n"
          ]
        }
      ],
      "source": [
        "env_green = gnwrapper.Animation(cr.CarRacing())\n",
        "env_green = cr.CarRacing(color = 'g')\n",
        "obs = env_green.reset()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "YLekXvPFZEmp"
      },
      "outputs": [],
      "source": [
        "def get_random(state):\n",
        "    red_scale, green_scale, blue_scale = 1., 1., 1.\n",
        "    base_scale = 0.5\n",
        "    while (red_scale == green_scale == blue_scale):\n",
        "        add_green = random.randint(0, 1)\n",
        "        add_red = random.randint(0, 1)\n",
        "        add_blue = random.randint(0, 1)\n",
        "        if (add_red): \n",
        "            red_scale = random.uniform(0.5, 1.1)\n",
        "        if (add_green): \n",
        "            green_scale = random.uniform(0.5, 1.1)\n",
        "        if (add_blue): \n",
        "            blue_scale = random.uniform(0.5, 1.1)\n",
        "            \n",
        "    for i in range (0, 4):\n",
        "        s = torch.transpose(state[i], 0, 2)\n",
        "        road = s [1] - s [0] * 0.6 - s[2] * 0.4\n",
        "        road = torch.stack((road, road, road), 0)\n",
        "        ones = torch.ones(3, 96, 96).to(device)\n",
        "\n",
        "        road_mask = torch.logical_xor(road, ones)\n",
        "        road_layer = s * road_mask\n",
        "\n",
        "        light_green = 204 / 128. - 1\n",
        "        light_green_mask = torch.logical_xor(s - light_green , ones)\n",
        "        light_green_layer = s * light_green_mask\n",
        "\n",
        "        dark_green = 230 / 128. - 1\n",
        "        dark_green_mask = torch.logical_xor(s - dark_green , ones)\n",
        "        dark_green_layer = s * dark_green_mask\n",
        "\n",
        "        bg_layer = light_green_layer + dark_green_layer\n",
        "\n",
        "        ones = torch.ones(96, 96).to(device)\n",
        "        back_ground_mask = torch.logical_xor(bg_layer[1], ones)\n",
        "\n",
        "        red_channel = (back_ground_mask * 128) /128. - 1\n",
        "        green_channel = (back_ground_mask * 128) /128. - 1\n",
        "        blue_channel = (back_ground_mask * 128) /128. - 1\n",
        "\n",
        "        if (add_red): red_channel = bg_layer[1] * red_scale\n",
        "        if (add_green): green_channel = bg_layer[1] * green_scale\n",
        "        if (add_blue): blue_channel = bg_layer[1] * blue_scale\n",
        "\n",
        "        new_bg_layer = torch.stack((red_channel, green_channel, blue_channel), 0)\n",
        "\n",
        "        new_state = new_bg_layer + road_layer\n",
        "\n",
        "        state[i] = torch.transpose(new_state, 0, 2)\n",
        "        \n",
        "    return state  \n",
        "\n",
        "def get_random_buffer(buffer, batch_size):\n",
        "    target_buffer = buffer.clone()\n",
        "    for i in range (batch_size):\n",
        "        target_buffer[i] = get_random(target_buffer[i])\n",
        "    return target_buffer    "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Env():\n",
        "    def __init__(self, color, seed = 0):\n",
        "        self.env = gnwrapper.Animation(cr.CarRacing(color = color))\n",
        "        self.env = cr.CarRacing(color = color)\n",
        "        self.color = color\n",
        "        self.env.seed(seed)\n",
        "        self.reward_threshold = 1000\n",
        "\n",
        "    def reset(self):\n",
        "        self.counter = 0\n",
        "        self.av_r = self.reward_memory()\n",
        "\n",
        "        self.die = False\n",
        "        img_rgb = self.env.reset()\n",
        "        img_rgb = img_rgb / 128. - 1\n",
        "        self.stack = [img_rgb] * 4\n",
        "        return np.array(self.stack)\n",
        "\n",
        "    def step(self, action):\n",
        "        total_reward = 0\n",
        "        for i in range(8):\n",
        "            img_rgb, reward, die, _ = self.env.step(action)\n",
        "\n",
        "            if die: reward += 100\n",
        "\n",
        "            if self.color == 'g' and np.mean(img_rgb[:, :, 1]) > 185.0:\n",
        "                  reward -= 0.05\n",
        "\n",
        "            total_reward += reward\n",
        "\n",
        "            done = True if self.av_r(reward) <= -0.1 else False\n",
        "            if done or die:\n",
        "                break\n",
        "\n",
        "        img_rgb = img_rgb / 128. - 1\n",
        "        self.stack.pop(0)\n",
        "        self.stack.append(img_rgb)\n",
        "        assert len(self.stack) == 4\n",
        "        return np.array(self.stack), total_reward, done, die\n",
        "\n",
        "    def step_eval(self, action):\n",
        "        img_rgb, reward, done, _ = self.env.step(action)\n",
        "\n",
        "        img_rgb = img_rgb / 128. - 1\n",
        "        self.stack.pop(0)\n",
        "        self.stack.append(img_rgb)\n",
        "        return np.array(self.stack), reward, done, _\n",
        "\n",
        "    def render(self, *arg):\n",
        "        self.env.render(*arg)\n",
        "\n",
        "    @staticmethod\n",
        "    def reward_memory():\n",
        "        count = 0\n",
        "        length = 100\n",
        "        history = np.zeros(length)\n",
        "\n",
        "        def memory(reward):\n",
        "            nonlocal count\n",
        "            history[count] = reward\n",
        "            count = (count + 1) % length\n",
        "            return np.mean(history)\n",
        "\n",
        "        return memory"
      ],
      "metadata": {
        "id": "dlmD539yuATw"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "S7XcNI4dkKzr"
      },
      "outputs": [],
      "source": [
        "class ReverseLayerF(Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx, x, alpha):\n",
        "        ctx.alpha = alpha\n",
        "        return x.view_as(x)\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        output = grad_output.neg() * ctx.alpha\n",
        "        return output, None  \n",
        "\n",
        "class DANN(nn.Module):\n",
        "    def __init__(self, num_out = 2):\n",
        "        super(DANN, self).__init__()\n",
        "        self.sketch = nn.Sequential(\n",
        "            nn.Conv3d(4, 4, kernel_size=(1, 1, 3), stride=1),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "        self.feature = nn.Sequential(  # input shape (4, 96, 96)\n",
        "            nn.Conv2d(4, 8, kernel_size=4, stride=2),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(8, 16, kernel_size=3, stride=2),  # (8, 47, 47)\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(16, 32, kernel_size=3, stride=2),  # (16, 23, 23)\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32, 64, kernel_size=3, stride=2),  # (32, 11, 11)\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "\n",
        "        self.cnn_base = nn.Sequential(\n",
        "            nn.Conv2d(64, 128, kernel_size=3, stride=1),  # (64, 5, 5)\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(128, 256, kernel_size=3, stride=1),  # (128, 3, 3)\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "\n",
        "        self.domain_classifier = nn.Sequential(\n",
        "            # 1600, 512\n",
        "            nn.Linear(64 * 5 * 5, 512),\n",
        "            nn.BatchNorm1d(512),\n",
        "            nn.ReLU(True),\n",
        "            nn.Linear(512, 256),\n",
        "            nn.BatchNorm1d(256),\n",
        "            nn.ReLU(True),\n",
        "            nn.Linear(256, 2),\n",
        "        )\n",
        "\n",
        "        self.v = nn.Sequential(nn.Linear(256, 100), nn.ReLU(), nn.Linear(100, 1))\n",
        "        self.fc = nn.Sequential(nn.Linear(256, 100), nn.ReLU())\n",
        "        self.alpha_head = nn.Sequential(nn.Linear(100, 3), nn.Softplus())\n",
        "        self.beta_head = nn.Sequential(nn.Linear(100, 3), nn.Softplus())\n",
        "        self.apply(self._weights_init)\n",
        "      \n",
        "    def forward(self, input, a = 0.1):\n",
        "        sketch = self.sketch(input)\n",
        "        sketch = torch.squeeze(sketch)\n",
        "\n",
        "        feature = self.feature(sketch)\n",
        "\n",
        "        out = self.cnn_base(feature)\n",
        "        out = out.view(-1, 256)\n",
        "        v = self.v(out)\n",
        "        out = self.fc(out)\n",
        "\n",
        "        alpha = self.alpha_head(out) + 1\n",
        "        beta = self.beta_head(out) + 1\n",
        "\n",
        "        feature = feature.view(-1, 64 * 5 * 5)\n",
        "        reverse_feature = ReverseLayerF.apply(feature, a)\n",
        "        domain_output = self.domain_classifier(reverse_feature)\n",
        "\n",
        "        return (alpha, beta), v, domain_output, sketch\n",
        "\n",
        "    @staticmethod\n",
        "    def _weights_init(m):\n",
        "        if isinstance(m, nn.Conv2d):\n",
        "            nn.init.xavier_uniform_(m.weight, gain=nn.init.calculate_gain('relu'))\n",
        "            nn.init.constant_(m.bias, 0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "rzDylNjkZG55"
      },
      "outputs": [],
      "source": [
        "class Agent():\n",
        "    max_grad_norm = 0.5\n",
        "    clip_param = 0.1\n",
        "    ppo_epoch = 10\n",
        "\n",
        "    transition = np.dtype([('s', np.float64, (4, 96, 96, 3)), ('a', np.float64, (3,)), ('a_logp', np.float64),\n",
        "                       ('r', np.float64), ('s_', np.float64, (4, 96, 96, 3))])\n",
        "    def __init__(self, net, criterion, optimizer, buffer_capacity = 2000, batch_size = 128):\n",
        "        self.net = net\n",
        "        self.buffer_capacity = buffer_capacity\n",
        "        self.batch_size = batch_size\n",
        "        self.criterion = criterion\n",
        "        self.optimizer = optimizer\n",
        "\n",
        "        self.source_buffer = np.empty(self.buffer_capacity, dtype=self.transition)\n",
        "        self.counter = 0\n",
        "\n",
        "    def select_action(self, state):\n",
        "        state = torch.from_numpy(state).double().to(device).unsqueeze(0)\n",
        "        with torch.no_grad():\n",
        "            out = self.net.sketch(state)\n",
        "            out = torch.squeeze(out)\n",
        "            out = self.net.feature(out)\n",
        "\n",
        "            out = self.net.cnn_base(out)\n",
        "            out = out.view(-1, 256)\n",
        "            out = self.net.fc(out)\n",
        "            alpha = self.net.alpha_head(out) + 1\n",
        "            beta = self.net.beta_head(out) + 1\n",
        "\n",
        "        dist = Beta(alpha, beta)\n",
        "        action = dist.sample()\n",
        "        a_logp = dist.log_prob(action).sum(dim=1)\n",
        "\n",
        "        action = action.squeeze().cpu().numpy()\n",
        "        a_logp = a_logp.item()\n",
        "        return action, a_logp\n",
        "\n",
        "    def store(self, transition):\n",
        "        self.source_buffer[self.counter] = transition\n",
        "        self.counter += 1\n",
        "        if self.counter == self.buffer_capacity:\n",
        "            self.counter = 0\n",
        "            return True\n",
        "\n",
        "        return False\n",
        "\n",
        "    def update(self, epoch, eta = 0.1):\n",
        "        s = torch.tensor(self.source_buffer['s'], dtype=torch.double).to(device)\n",
        "        a = torch.tensor(self.source_buffer['a'], dtype=torch.double).to(device)\n",
        "        r = torch.tensor(self.source_buffer['r'], dtype=torch.double).to(device).view(-1, 1)\n",
        "        s_ = torch.tensor(self.source_buffer['s_'], dtype=torch.double).to(device)\n",
        "        old_a_logp = torch.tensor(self.source_buffer['a_logp'], dtype=torch.double).to(device).view(-1, 1)\n",
        "\n",
        "        source_domain_label = torch.zeros(self.batch_size).long()\n",
        "        target_domain_label = torch.ones(self.batch_size).long()\n",
        "        source_domain_label = source_domain_label.to(device)\n",
        "        target_domain_label = target_domain_label.to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            target_v = r + 0.99 * self.net(s_)[1]\n",
        "            adv = target_v - self.net(s)[1]\n",
        "\n",
        "        image_array = []\n",
        "        source_acc_array = []\n",
        "        target_acc_array = []\n",
        "        for _ in range(self.ppo_epoch):\n",
        "            total = 0\n",
        "            source_domain_correct = 0\n",
        "            tagret_domain_correct = 0\n",
        "            add_image = True\n",
        "            \n",
        "            for index in BatchSampler(SubsetRandomSampler(range(self.buffer_capacity)), self.batch_size, True):\n",
        "                total += self.batch_size\n",
        "                loss = 0\n",
        "                \n",
        "                with torch.no_grad():\n",
        "                    target_batch = get_random_buffer(s[index], self.batch_size)\n",
        "                \n",
        "\n",
        "                (alpha, beta), v, domain_out, s_sketch = self.net(s[index], eta)\n",
        "                source_domain_loss = self.criterion(domain_out, source_domain_label)\n",
        "\n",
        "                _, predicted = torch.max(domain_out.data, 1)\n",
        "                source_domain_correct += predicted.eq(source_domain_label.data).cpu().sum().item()\n",
        "\n",
        "                _, _,  domain_out, t_sketch = self.net(target_batch, eta)\n",
        "                target_domain_loss = self.criterion(domain_out, target_domain_label)\n",
        "\n",
        "                _, predicted = torch.max(domain_out.data, 1)\n",
        "                tagret_domain_correct += predicted.eq(target_domain_label.data).cpu().sum().item()\n",
        "                \n",
        "                if (add_image):\n",
        "                    image = s_sketch[0][0].reshape(96, 96)\n",
        "                    image = image.cpu().detach().numpy()\n",
        "                    image_array.append(image)\n",
        "                \n",
        "                    image = t_sketch[0][0].reshape(96, 96)\n",
        "                    image = image.cpu().detach().numpy()\n",
        "                    image_array.append(image)\n",
        "                    \n",
        "                    add_image = False\n",
        "\n",
        "                dist = Beta(alpha, beta)\n",
        "                a_logp = dist.log_prob(a[index]).sum(dim=1, keepdim=True)\n",
        "                ratio = torch.exp(a_logp - old_a_logp[index])\n",
        "                surr1 = ratio * adv[index]\n",
        "                surr2 = torch.clamp(ratio, 1.0 - self.clip_param, 1.0 + self.clip_param) * adv[index]\n",
        "                action_loss = -torch.min(surr1, surr2).mean()\n",
        "                value_loss = F.smooth_l1_loss(self.net(s[index])[1], target_v[index])\n",
        "\n",
        "                loss += action_loss + 2. * value_loss + source_domain_loss + target_domain_loss\n",
        "\n",
        "                self.optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                self.optimizer.step()\n",
        "\n",
        "            source_acc_array.append( source_domain_correct / total )\n",
        "            target_acc_array.append( tagret_domain_correct / total )\n",
        "        \n",
        "        source_acc_mean = 0\n",
        "        print(\"Source acc\", end = ' ')\n",
        "        for acc in source_acc_array:\n",
        "            source_acc_mean += acc\n",
        "            print(\"%.2f\" % acc, end = ' ')\n",
        "        print(\" \")\n",
        "        target_acc_mean = 0\n",
        "        print(\"Target acc\", end = ' ')\n",
        "        for acc in target_acc_array:\n",
        "            target_acc_mean += acc\n",
        "            print(\"%.2f\" % acc, end = ' ')\n",
        "        print(\" \")\n",
        "            \n",
        "        f, axs = plt.subplots(2, 10, figsize = (16, 4))\n",
        "        axs = axs.flatten()\n",
        "        for img, ax in zip(image_array, axs):\n",
        "            ax.imshow(img)\n",
        "        f.savefig('./output_r/%04d.png' % epoch)\n",
        "        plt.close(f)\n",
        "        \n",
        "        return source_acc_mean / 10 , target_acc_mean / 10"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def eval(agent, env):\n",
        "    score = 0\n",
        "    state = env.reset()\n",
        "\n",
        "    for t in range(1000):\n",
        "        action, a_logp = agent.select_action(state)\n",
        "\n",
        "        state_, reward, done, _ = env.step_eval(action * np.array([2., 1., 1.]) + np.array([-1., 0., 0.]))\n",
        "\n",
        "        score += reward\n",
        "\n",
        "        state = state_\n",
        "\n",
        "        if done:\n",
        "            break\n",
        "\n",
        "    return score"
      ],
      "metadata": {
        "id": "sNwLvWRQuENp"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(source_env, target_env, agent):\n",
        "    training_records= []\n",
        "    running_score_records = []\n",
        "    running_score = 0\n",
        "    \n",
        "    c1_running_score = 0\n",
        "    c1_training_records = []\n",
        "    c1_running_score_records = []\n",
        "    \n",
        "    c2_running_score = 0\n",
        "    c2_training_records = []\n",
        "    c2_running_score_records = []\n",
        "    \n",
        "    eta = 0.2\n",
        "\n",
        "    for i_ep in range(3000):\n",
        "        score = 0\n",
        "        state = source_env.reset()\n",
        "\n",
        "        for t in range(1000):\n",
        "            action, a_logp = agent.select_action(state)\n",
        "            state_, reward, done, die = source_env.step(action * np.array([2., 1., 1.])\\\n",
        "                                                                       + np.array([-1., 0., 0.]))\n",
        "            score += reward\n",
        "\n",
        "            should_update = agent.store((state, action, a_logp, reward, state_))\n",
        "\n",
        "            if should_update: \n",
        "                if (i_ep < 500): eta_max =  0.5\n",
        "                elif (i_ep < 1500): eta_max = 0.45\n",
        "                else: eta_max = 0.3\n",
        "                    \n",
        "                print(\"eta: %.2f\" % eta)\n",
        "                s_acc, t_acc = agent.update(epoch = i_ep, eta = eta)\n",
        "                \n",
        "                if (s_acc > 0.95 or t_acc > 0.95):\n",
        "                    eta = min(eta + 0.1, eta_max)\n",
        "                elif (s_acc > 0.9 or t_acc > 0.9):\n",
        "                    eta = min(eta + 0.05, eta_max)\n",
        "                else:\n",
        "                    if (i_ep < 500): eta = 0.2\n",
        "                    elif (i_ep < 1500): eta = 0.15\n",
        "                    else: eta = 0.1\n",
        "\n",
        "            state = state_\n",
        "\n",
        "            if done or die: break\n",
        "                \n",
        "        training_records.append(score)\n",
        "        running_score = running_score * 0.99 + score * 0.01\n",
        "        running_score_records.append(running_score)\n",
        "        \n",
        "        c1_score = eval(agent, target_env[0])\n",
        "        c2_score = eval(agent, target_env[1])\n",
        "        c1_training_records.append(c1_score)\n",
        "        c2_training_records.append(c2_score)\n",
        "        \n",
        "        c1_running_score = c1_running_score * 0.99 + c1_score * 0.01\n",
        "        c2_running_score = c2_running_score * 0.99 + c2_score * 0.01\n",
        "        c1_running_score_records.append(c1_running_score)\n",
        "        c2_running_score_records.append(c2_running_score)\n",
        "        \n",
        "        if (i_ep % 10 == 0):\n",
        "            print('Ep {}\\tLast score: {:.2f}\\tMoving average score: {:.2f}'.format(i_ep, score, running_score))\n",
        "            print('c1 score: {:.2f}\\t c1 Moving average: {:.2f}'.format(c1_score, c1_running_score))\n",
        "            print('c2 score: {:.2f}\\t c2 Moving average: {:.2f}'.format(c2_score, c2_running_score))\n",
        "            \n",
        "            if (i_ep != 0):\n",
        "                f, axs = plt.subplots(1, 2, figsize = (16, 8))\n",
        "                axs[0].plot(range(len(training_records)), training_records)\n",
        "                axs[0].plot(range(len(c1_training_records)), c1_training_records)\n",
        "                axs[0].plot(range(len(c2_training_records)), c2_training_records)\n",
        "                \n",
        "                axs[1].plot(range(len(running_score_records)), running_score_records)\n",
        "                axs[1].plot(range(len(c1_running_score_records)), c1_running_score_records)\n",
        "                axs[1].plot(range(len(c2_running_score_records)), c2_running_score_records)\n",
        "                \n",
        "                axs[0].legend(['s', 'c1', 'c2'])\n",
        "                axs[1].legend(['s', 'c1', 'c2'])\n",
        "\n",
        "                f.savefig('./output_r/result_%04d.png' % i_ep)\n",
        "                plt.close(f)\n",
        "\n",
        "            \n",
        "        "
      ],
      "metadata": {
        "id": "dpsGkxvBuGLw"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "green_env = Env(color = 'g', seed = 0)\n",
        "env_c1 = Env(color = 'c1', seed = 0)\n",
        "env_c2 = Env(color = 'c2', seed = 0)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss().cuda()\n",
        "net = DANN(num_out = 2).double().cuda()\n",
        "optimizer = optim.Adam(net.parameters(), lr=1e-3)\n",
        "agent = Agent(net = net,  criterion = criterion,  optimizer = optimizer, buffer_capacity = 2048, batch_size = 128)\n",
        "\n",
        "source_env = green_env\n",
        "target_env = [env_c1, env_c2]\n",
        "train(green_env, target_env, agent)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QYyXQG04uHp8",
        "outputId": "d57e8a01-2f89-414c-ce28-2e8c5889f5f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gym/spaces/box.py:74: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
            "  \"Box bound precision lowered by casting to {}\".format(self.dtype)\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "name": "car_racing_colab.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}