{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hpANlTAssfdF"
      },
      "source": [
        "# Colab env settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UfHgya4Jsdas",
        "outputId": "e7b32543-63be-4e01-edc3-2d7091693065"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'car_racing'...\n",
            "remote: Enumerating objects: 66, done.\u001b[K\n",
            "remote: Counting objects: 100% (66/66), done.\u001b[K\n",
            "remote: Compressing objects: 100% (58/58), done.\u001b[K\n",
            "remote: Total 66 (delta 34), reused 18 (delta 7), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (66/66), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/bochendong/car_racing.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yX7L7IlDnyvU"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!sudo apt update && sudo apt install python-opengl\n",
        "!sudo apt update && sudo apt install xvfb\n",
        "!pip install gym-notebook-wrapper stable-baselines[mpi] box2d box2d-kengz pyvirtualdisplay pyglet\n",
        "!pip install wandb\n",
        "!pip install pyvirtualdisplay -qq\n",
        "!pip install folium==0.2.1\n",
        "!apt-get install -y xvfb python-opengl ffmpeg -qq"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install box2d"
      ],
      "metadata": {
        "id": "n4GnViajtd1B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zUgm5ewmnyvV"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import random\n",
        "\n",
        "from PIL import Image\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import namedtuple\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as T\n",
        "import torch.optim as optim\n",
        "from torch.distributions import Beta\n",
        "from torch.utils.data.sampler import BatchSampler, SubsetRandomSampler\n",
        "\n",
        "from torch.autograd import Function\n",
        "\n",
        "import gnwrapper\n",
        "import gym\n",
        "from gym import logger as gymlogger\n",
        "gymlogger.set_level(30)\n",
        "\n",
        "from IPython.display import HTML\n",
        "from IPython import display as ipythondisplay\n",
        "from pyvirtualdisplay import Display\n",
        "import wandb\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import glob"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd car_racing"
      ],
      "metadata": {
        "id": "NGrLEYQbtqWv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import car_racing as cr\n",
        "\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "print(device)\n",
        "\n",
        "if (os.path.exists(\"./output_r\")) == False:\n",
        "    os.mkdir(\"output_r\")\n",
        "    \n",
        "for epoch in range (3000):\n",
        "    files = glob.glob(\"./output_r/*.png\")\n",
        "\n",
        "    for f in files:\n",
        "        os.remove(f)"
      ],
      "metadata": {
        "id": "qmqqcZfbtj63"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nu12ch3KssCE"
      },
      "source": [
        "# Car_racing Enviorment settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0bSmOb2d6qPq"
      },
      "outputs": [],
      "source": [
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HBhiAnYKnyvZ",
        "outputId": "46e12f43-f0c6-4d3f-b059-aff4df856795"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
            "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
            "/usr/local/lib/python3.7/dist-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
            "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
          ]
        }
      ],
      "source": [
        "env_green = gnwrapper.Animation(cr.CarRacing())\n",
        "env_green = cr.CarRacing(color = 'g')\n",
        "obs = env_green.reset()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YLekXvPFZEmp"
      },
      "outputs": [],
      "source": [
        "def get_random(state):\n",
        "    red_scale, green_scale, blue_scale = 1., 1., 1.\n",
        "    base_scale = 0.5\n",
        "    while (red_scale == green_scale == blue_scale):\n",
        "        add_green = random.randint(0, 1)\n",
        "        add_red = random.randint(0, 1)\n",
        "        add_blue = random.randint(0, 1)\n",
        "        if (add_red): \n",
        "            red_scale = random.uniform(0.5, 1.1)\n",
        "        if (add_green): \n",
        "            green_scale = random.uniform(0.5, 1.1)\n",
        "        if (add_blue): \n",
        "            blue_scale = random.uniform(0.5, 1.1)\n",
        "            \n",
        "    for i in range (0, 4):\n",
        "        s = torch.transpose(state[i], 0, 2)\n",
        "        road = s [1] - s [0] * 0.6 - s[2] * 0.4\n",
        "        road = torch.stack((road, road, road), 0)\n",
        "        ones = torch.ones(3, 96, 96).to(device)\n",
        "\n",
        "        road_mask = torch.logical_xor(road, ones)\n",
        "        road_layer = s * road_mask\n",
        "\n",
        "        light_green = 204 / 128. - 1\n",
        "        light_green_mask = torch.logical_xor(s - light_green , ones)\n",
        "        light_green_layer = s * light_green_mask\n",
        "\n",
        "        dark_green = 230 / 128. - 1\n",
        "        dark_green_mask = torch.logical_xor(s - dark_green , ones)\n",
        "        dark_green_layer = s * dark_green_mask\n",
        "\n",
        "        bg_layer = light_green_layer + dark_green_layer\n",
        "\n",
        "        ones = torch.ones(96, 96).to(device)\n",
        "        back_ground_mask = torch.logical_xor(bg_layer[1], ones)\n",
        "\n",
        "        red_channel = (back_ground_mask * 128) /128. - 1\n",
        "        green_channel = (back_ground_mask * 128) /128. - 1\n",
        "        blue_channel = (back_ground_mask * 128) /128. - 1\n",
        "\n",
        "        if (add_red): red_channel = bg_layer[1] * red_scale\n",
        "        if (add_green): green_channel = bg_layer[1] * green_scale\n",
        "        if (add_blue): blue_channel = bg_layer[1] * blue_scale\n",
        "\n",
        "        new_bg_layer = torch.stack((red_channel, green_channel, blue_channel), 0)\n",
        "\n",
        "        new_state = new_bg_layer + road_layer\n",
        "\n",
        "        state[i] = torch.transpose(new_state, 0, 2)\n",
        "        \n",
        "    return state  \n",
        "\n",
        "def get_random_buffer(buffer, batch_size):\n",
        "    target_buffer = buffer.clone()\n",
        "    for i in range (batch_size):\n",
        "        target_buffer[i] = get_random(target_buffer[i])\n",
        "    return target_buffer    "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Env():\n",
        "    def __init__(self, color, seed = 0):\n",
        "        self.env = gnwrapper.Animation(cr.CarRacing(color = color))\n",
        "        self.env = cr.CarRacing(color = color)\n",
        "        self.color = color\n",
        "        self.env.seed(seed)\n",
        "        self.reward_threshold = 1000\n",
        "\n",
        "    def reset(self):\n",
        "        self.counter = 0\n",
        "        self.av_r = self.reward_memory()\n",
        "\n",
        "        self.die = False\n",
        "        img_rgb = self.env.reset()\n",
        "        img_rgb = img_rgb / 128. - 1\n",
        "        self.stack = [img_rgb] * 4\n",
        "        return np.array(self.stack)\n",
        "\n",
        "    def step(self, action):\n",
        "        total_reward = 0\n",
        "        for i in range(8):\n",
        "            img_rgb, reward, die, _ = self.env.step(action)\n",
        "\n",
        "            if die: reward += 100\n",
        "\n",
        "            if self.color == 'g' and np.mean(img_rgb[:, :, 1]) > 185.0:\n",
        "                  reward -= 0.05\n",
        "\n",
        "            total_reward += reward\n",
        "\n",
        "            done = True if self.av_r(reward) <= -0.1 else False\n",
        "            if done or die:\n",
        "                break\n",
        "\n",
        "        img_rgb = img_rgb / 128. - 1\n",
        "        self.stack.pop(0)\n",
        "        self.stack.append(img_rgb)\n",
        "        assert len(self.stack) == 4\n",
        "        return np.array(self.stack), total_reward, done, die\n",
        "\n",
        "    def step_eval(self, action):\n",
        "        img_rgb, reward, done, _ = self.env.step(action)\n",
        "\n",
        "        img_rgb = img_rgb / 128. - 1\n",
        "        self.stack.pop(0)\n",
        "        self.stack.append(img_rgb)\n",
        "        return np.array(self.stack), reward, done, _\n",
        "\n",
        "    def render(self, *arg):\n",
        "        self.env.render(*arg)\n",
        "\n",
        "    @staticmethod\n",
        "    def reward_memory():\n",
        "        count = 0\n",
        "        length = 100\n",
        "        history = np.zeros(length)\n",
        "\n",
        "        def memory(reward):\n",
        "            nonlocal count\n",
        "            history[count] = reward\n",
        "            count = (count + 1) % length\n",
        "            return np.mean(history)\n",
        "\n",
        "        return memory"
      ],
      "metadata": {
        "id": "dlmD539yuATw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S7XcNI4dkKzr"
      },
      "outputs": [],
      "source": [
        "class ReverseLayerF(Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx, x, alpha):\n",
        "        ctx.alpha = alpha\n",
        "        return x.view_as(x)\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        output = grad_output.neg() * ctx.alpha\n",
        "        return output, None  \n",
        "\n",
        "class DANN(nn.Module):\n",
        "    def __init__(self, num_out = 2):\n",
        "        super(DANN, self).__init__()\n",
        "        self.sketch = nn.Sequential(\n",
        "            nn.Conv3d(4, 4, kernel_size=(1, 1, 3), stride=1),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "        self.feature = nn.Sequential(  # input shape (4, 96, 96)\n",
        "            nn.Conv2d(4, 8, kernel_size=4, stride=2),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(8, 16, kernel_size=3, stride=2),  # (8, 47, 47)\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(16, 32, kernel_size=3, stride=2),  # (16, 23, 23)\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32, 64, kernel_size=3, stride=2),  # (32, 11, 11)\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "\n",
        "        self.cnn_base = nn.Sequential(\n",
        "            nn.Conv2d(64, 128, kernel_size=3, stride=1),  # (64, 5, 5)\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(128, 256, kernel_size=3, stride=1),  # (128, 3, 3)\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "\n",
        "        self.domain_classifier = nn.Sequential(\n",
        "            # 1600, 512\n",
        "            nn.Linear(64 * 5 * 5, 512),\n",
        "            nn.BatchNorm1d(512),\n",
        "            nn.ReLU(True),\n",
        "            nn.Linear(512, 256),\n",
        "            nn.BatchNorm1d(256),\n",
        "            nn.ReLU(True),\n",
        "            nn.Linear(256, 2),\n",
        "        )\n",
        "\n",
        "        self.v = nn.Sequential(nn.Linear(256, 100), nn.ReLU(), nn.Linear(100, 1))\n",
        "        self.fc = nn.Sequential(nn.Linear(256, 100), nn.ReLU())\n",
        "        self.alpha_head = nn.Sequential(nn.Linear(100, 3), nn.Softplus())\n",
        "        self.beta_head = nn.Sequential(nn.Linear(100, 3), nn.Softplus())\n",
        "        self.apply(self._weights_init)\n",
        "      \n",
        "    def forward(self, input, a = 0.1):\n",
        "        sketch = self.sketch(input)\n",
        "        sketch = torch.squeeze(sketch)\n",
        "\n",
        "        feature = self.feature(sketch)\n",
        "\n",
        "        out = self.cnn_base(feature)\n",
        "        out = out.view(-1, 256)\n",
        "        v = self.v(out)\n",
        "        out = self.fc(out)\n",
        "\n",
        "        alpha = self.alpha_head(out) + 1\n",
        "        beta = self.beta_head(out) + 1\n",
        "\n",
        "        feature = feature.view(-1, 64 * 5 * 5)\n",
        "        reverse_feature = ReverseLayerF.apply(feature, a)\n",
        "        domain_output = self.domain_classifier(reverse_feature)\n",
        "\n",
        "        return (alpha, beta), v, domain_output, sketch\n",
        "\n",
        "    @staticmethod\n",
        "    def _weights_init(m):\n",
        "        if isinstance(m, nn.Conv2d):\n",
        "            nn.init.xavier_uniform_(m.weight, gain=nn.init.calculate_gain('relu'))\n",
        "            nn.init.constant_(m.bias, 0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rzDylNjkZG55",
        "outputId": "a62b8778-8367-4567-dce9-48a7a0f4d53c"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 864x288 with 8 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "class Agent():\n",
        "    max_grad_norm = 0.5\n",
        "    clip_param = 0.1\n",
        "    ppo_epoch = 10\n",
        "\n",
        "    transition = np.dtype([('s', np.float64, (4, 96, 96, 3)), ('a', np.float64, (3,)), ('a_logp', np.float64),\n",
        "                       ('r', np.float64), ('s_', np.float64, (4, 96, 96, 3))])\n",
        "    def __init__(self, net, criterion, optimizer, buffer_capacity = 2000, batch_size = 128):\n",
        "        self.net = net\n",
        "        self.buffer_capacity = buffer_capacity\n",
        "        self.batch_size = batch_size\n",
        "        self.criterion = criterion\n",
        "        self.optimizer = optimizer\n",
        "\n",
        "        self.source_buffer = np.empty(self.buffer_capacity, dtype=self.transition)\n",
        "        self.counter = 0\n",
        "\n",
        "    def select_action(self, state):\n",
        "        state = torch.from_numpy(state).double().to(device).unsqueeze(0)\n",
        "        with torch.no_grad():\n",
        "            out = self.net.sketch(state)\n",
        "            out = torch.squeeze(out)\n",
        "            out = self.net.feature(out)\n",
        "\n",
        "            out = self.net.cnn_base(out)\n",
        "            out = out.view(-1, 256)\n",
        "            out = self.net.fc(out)\n",
        "            alpha = self.net.alpha_head(out) + 1\n",
        "            beta = self.net.beta_head(out) + 1\n",
        "\n",
        "        dist = Beta(alpha, beta)\n",
        "        action = dist.sample()\n",
        "        a_logp = dist.log_prob(action).sum(dim=1)\n",
        "\n",
        "        action = action.squeeze().cpu().numpy()\n",
        "        a_logp = a_logp.item()\n",
        "        return action, a_logp\n",
        "\n",
        "    def store(self, transition):\n",
        "        self.source_buffer[self.counter] = transition\n",
        "        self.counter += 1\n",
        "        if self.counter == self.buffer_capacity:\n",
        "            self.counter = 0\n",
        "            return True\n",
        "\n",
        "        return False\n",
        "\n",
        "    def update(self, epoch, eta = 0.1):\n",
        "        s = torch.tensor(self.source_buffer['s'], dtype=torch.double).to(device)\n",
        "        a = torch.tensor(self.source_buffer['a'], dtype=torch.double).to(device)\n",
        "        r = torch.tensor(self.source_buffer['r'], dtype=torch.double).to(device).view(-1, 1)\n",
        "        s_ = torch.tensor(self.source_buffer['s_'], dtype=torch.double).to(device)\n",
        "        old_a_logp = torch.tensor(self.source_buffer['a_logp'], dtype=torch.double).to(device).view(-1, 1)\n",
        "\n",
        "        source_domain_label = torch.zeros(self.batch_size).long()\n",
        "        target_domain_label = torch.ones(self.batch_size).long()\n",
        "        source_domain_label = source_domain_label.to(device)\n",
        "        target_domain_label = target_domain_label.to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            target_v = r + 0.99 * self.net(s_)[1]\n",
        "            adv = target_v - self.net(s)[1]\n",
        "\n",
        "        image_array = []\n",
        "        source_acc_array = []\n",
        "        target_acc_array = []\n",
        "        for _ in range(self.ppo_epoch):\n",
        "            total = 0\n",
        "            source_domain_correct = 0\n",
        "            tagret_domain_correct = 0\n",
        "            add_image = True\n",
        "            \n",
        "            for index in BatchSampler(SubsetRandomSampler(range(self.buffer_capacity)), self.batch_size, True):\n",
        "                total += self.batch_size\n",
        "                loss = 0\n",
        "                \n",
        "                with torch.no_grad():\n",
        "                    target_batch = get_random_buffer(s[index], self.batch_size)\n",
        "                \n",
        "\n",
        "                (alpha, beta), v, domain_out, s_sketch = self.net(s[index], eta)\n",
        "                source_domain_loss = self.criterion(domain_out, source_domain_label)\n",
        "\n",
        "                _, predicted = torch.max(domain_out.data, 1)\n",
        "                source_domain_correct += predicted.eq(source_domain_label.data).cpu().sum().item()\n",
        "\n",
        "                _, _,  domain_out, t_sketch = self.net(target_batch, eta)\n",
        "                target_domain_loss = self.criterion(domain_out, target_domain_label)\n",
        "\n",
        "                _, predicted = torch.max(domain_out.data, 1)\n",
        "                tagret_domain_correct += predicted.eq(target_domain_label.data).cpu().sum().item()\n",
        "                \n",
        "                if (add_image):\n",
        "                    image = s_sketch[0][0].reshape(96, 96)\n",
        "                    image = image.cpu().detach().numpy()\n",
        "                    image_array.append(image)\n",
        "                \n",
        "                    image = t_sketch[0][0].reshape(96, 96)\n",
        "                    image = image.cpu().detach().numpy()\n",
        "                    image_array.append(image)\n",
        "                    \n",
        "                    add_image = False\n",
        "\n",
        "                dist = Beta(alpha, beta)\n",
        "                a_logp = dist.log_prob(a[index]).sum(dim=1, keepdim=True)\n",
        "                ratio = torch.exp(a_logp - old_a_logp[index])\n",
        "                surr1 = ratio * adv[index]\n",
        "                surr2 = torch.clamp(ratio, 1.0 - self.clip_param, 1.0 + self.clip_param) * adv[index]\n",
        "                action_loss = -torch.min(surr1, surr2).mean()\n",
        "                value_loss = F.smooth_l1_loss(self.net(s[index])[1], target_v[index])\n",
        "\n",
        "                loss += action_loss + 2. * value_loss + source_domain_loss + target_domain_loss\n",
        "\n",
        "                self.optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                self.optimizer.step()\n",
        "\n",
        "            source_acc_array.append( source_domain_correct / total )\n",
        "            target_acc_array.append( tagret_domain_correct / total )\n",
        "        \n",
        "        source_acc_mean = 0\n",
        "        print(\"Source acc\", end = ' ')\n",
        "        for acc in source_acc_array:\n",
        "            source_acc_mean += acc\n",
        "            print(\"%.2f\" % acc, end = ' ')\n",
        "        print(\" \")\n",
        "        target_acc_mean = 0\n",
        "        print(\"Target acc\", end = ' ')\n",
        "        for acc in target_acc_array:\n",
        "            target_acc_mean += acc\n",
        "            print(\"%.2f\" % acc, end = ' ')\n",
        "        print(\" \")\n",
        "            \n",
        "        f, axs = plt.subplots(2, 10, figsize = (16, 4))\n",
        "        axs = axs.flatten()\n",
        "        for img, ax in zip(image_array, axs):\n",
        "            ax.imshow(img)\n",
        "        f.savefig('./output_r/%04d.png' % epoch)\n",
        "        plt.close(f)\n",
        "        \n",
        "        return source_acc_mean / 10 , target_acc_mean / 10"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def eval(agent, env):\n",
        "    score = 0\n",
        "    state = env.reset()\n",
        "\n",
        "    for t in range(1000):\n",
        "        action, a_logp = agent.select_action(state)\n",
        "\n",
        "        state_, reward, done, _ = env.step_eval(action * np.array([2., 1., 1.]) + np.array([-1., 0., 0.]))\n",
        "\n",
        "        score += reward\n",
        "\n",
        "        state = state_\n",
        "\n",
        "        if done:\n",
        "            break\n",
        "\n",
        "    return score"
      ],
      "metadata": {
        "id": "sNwLvWRQuENp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(source_env, target_env, agent):\n",
        "    training_records= []\n",
        "    running_score_records = []\n",
        "    running_score = 0\n",
        "    \n",
        "    c1_running_score = 0\n",
        "    c1_training_records = []\n",
        "    c1_running_score_records = []\n",
        "    \n",
        "    c2_running_score = 0\n",
        "    c2_training_records = []\n",
        "    c2_running_score_records = []\n",
        "    \n",
        "    eta = 0.2\n",
        "\n",
        "    for i_ep in range(3000):\n",
        "        score = 0\n",
        "        state = source_env.reset()\n",
        "\n",
        "        for t in range(1000):\n",
        "            action, a_logp = agent.select_action(state)\n",
        "            state_, reward, done, die = source_env.step(action * np.array([2., 1., 1.])\\\n",
        "                                                                       + np.array([-1., 0., 0.]))\n",
        "            score += reward\n",
        "\n",
        "            should_update = agent.store((state, action, a_logp, reward, state_))\n",
        "\n",
        "            if should_update: \n",
        "                if (i_ep < 500): eta_max =  0.5\n",
        "                elif (i_ep < 1500): eta_max = 0.45\n",
        "                else: eta_max = 0.3\n",
        "                    \n",
        "                print(\"eta: %.2f\" % eta)\n",
        "                s_acc, t_acc = agent.update(epoch = i_ep, eta = eta)\n",
        "                \n",
        "                if (s_acc > 0.95 or t_acc > 0.95):\n",
        "                    eta = min(eta + 0.1, eta_max)\n",
        "                elif (s_acc > 0.9 or t_acc > 0.9):\n",
        "                    eta = min(eta + 0.05, eta_max)\n",
        "                else:\n",
        "                    if (i_ep < 500): eta = 0.2\n",
        "                    elif (i_ep < 1500): eta = 0.15\n",
        "                    else: eta = 0.1\n",
        "\n",
        "            state = state_\n",
        "\n",
        "            if done or die: break\n",
        "                \n",
        "        training_records.append(score)\n",
        "        running_score = running_score * 0.99 + score * 0.01\n",
        "        running_score_records.append(running_score)\n",
        "        \n",
        "        c1_score = eval(agent, target_env[0])\n",
        "        c2_score = eval(agent, target_env[1])\n",
        "        c1_training_records.append(c1_score)\n",
        "        c2_training_records.append(c2_score)\n",
        "        \n",
        "        c1_running_score = c1_running_score * 0.99 + c1_score * 0.01\n",
        "        c2_running_score = c2_running_score * 0.99 + c2_score * 0.01\n",
        "        c1_running_score_records.append(c1_running_score)\n",
        "        c2_running_score_records.append(c2_running_score)\n",
        "        \n",
        "        if (i_ep % 10 == 0):\n",
        "            print('Ep {}\\tLast score: {:.2f}\\tMoving average score: {:.2f}'.format(i_ep, score, running_score))\n",
        "            print('c1 score: {:.2f}\\t c1 Moving average: {:.2f}'.format(c1_score, c1_running_score))\n",
        "            print('c2 score: {:.2f}\\t c2 Moving average: {:.2f}'.format(c2_score, c2_running_score))\n",
        "            \n",
        "            if (i_ep != 0):\n",
        "                f, axs = plt.subplots(1, 2, figsize = (16, 8))\n",
        "                axs[0].plot(range(len(training_records)), training_records)\n",
        "                axs[0].plot(range(len(c1_training_records)), c1_training_records)\n",
        "                axs[0].plot(range(len(c2_training_records)), c2_training_records)\n",
        "                \n",
        "                axs[1].plot(range(len(running_score_records)), running_score_records)\n",
        "                axs[1].plot(range(len(c1_running_score_records)), c1_running_score_records)\n",
        "                axs[1].plot(range(len(c2_running_score_records)), c2_running_score_records)\n",
        "                \n",
        "                axs[0].legend(['s', 'c1', 'c2'])\n",
        "                axs[1].legend(['s', 'c1', 'c2'])\n",
        "\n",
        "                f.savefig('./output_r/result_%04d.png' % i_ep)\n",
        "                plt.close(f)\n",
        "\n",
        "            \n",
        "        "
      ],
      "metadata": {
        "id": "dpsGkxvBuGLw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "green_env = Env(color = 'g', seed = 0)\n",
        "env_c1 = Env(color = 'c1', seed = 0)\n",
        "env_c2 = Env(color = 'c2', seed = 0)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss().cuda()\n",
        "net = DANN(num_out = 2).double().cuda()\n",
        "optimizer = optim.Adam(net.parameters(), lr=1e-3)\n",
        "agent = Agent(net = net,  criterion = criterion,  optimizer = optimizer, buffer_capacity = 2048, batch_size = 128)\n",
        "\n",
        "source_env = green_env\n",
        "target_env = [env_c1, env_c2]\n",
        "train(green_env, target_env, agent)"
      ],
      "metadata": {
        "id": "QYyXQG04uHp8"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "name": "car_racing_colab.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}