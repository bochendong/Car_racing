{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bochendong/car_racing/blob/main/%E2%80%9Cdsn_ipynb%E2%80%9D%E7%9A%84%E5%89%AF%E6%9C%AC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Global Enviorment Settings"
      ],
      "metadata": {
        "id": "sXw-vOXxju2p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/bochendong/car_racing.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kyiqjBTljuBC",
        "outputId": "5a4c891c-9580-4f73-ee37-0430ea2e68e7"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'car_racing' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!sudo apt update && sudo apt install python-opengl\n",
        "!sudo apt update && sudo apt install xvfb\n",
        "!pip install gym-notebook-wrapper stable-baselines[mpi] box2d box2d-kengz pyvirtualdisplay pyglet\n",
        "!pip install wandb\n",
        "!pip install gym==0.21.0\n",
        "!pip install pyvirtualdisplay -qq\n",
        "!pip install folium==0.2.1\n",
        "!apt-get install -y xvfb python-opengl ffmpeg -qq\n",
        "!pip install box2d"
      ],
      "metadata": {
        "id": "6dYb1D3hjzdc"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import random\n",
        "\n",
        "from PIL import Image\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import namedtuple\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as T\n",
        "import torch.optim as optim\n",
        "from torch.distributions import Beta\n",
        "from torch.utils.data.sampler import BatchSampler, SubsetRandomSampler\n",
        "\n",
        "from torch.autograd import Function\n",
        "\n",
        "import gnwrapper\n",
        "import gym\n",
        "from gym import logger as gymlogger\n",
        "gymlogger.set_level(30)\n",
        "\n",
        "from IPython.display import HTML\n",
        "from IPython import display as ipythondisplay\n",
        "from pyvirtualdisplay import Display\n",
        "import wandb\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import glob"
      ],
      "metadata": {
        "id": "zJDwIbQ9jry6"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd car_racing\n",
        "import car_racing as cr"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AqLJJUhAjoH7",
        "outputId": "5f64aa0c-f1eb-4c96-8f4e-c7692bb75d2c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/car_racing\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "print(device)\n",
        "\n",
        "if (os.path.exists(\"./output_r\")) == False:\n",
        "    os.mkdir(\"output_r\")\n",
        "    \n",
        "for epoch in range (3000):\n",
        "    files = glob.glob(\"./output_r/*.png\")\n",
        "\n",
        "    for f in files:\n",
        "        os.remove(f)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H6TQ87Bkjkzz",
        "outputId": "94dcc4f5-0bfa-4086-8156-34e2df3e6f0f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Car Racing Env Wrapper"
      ],
      "metadata": {
        "id": "w676toodj6G1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Env():\n",
        "    def __init__(self, color, seed = 0):\n",
        "        self.env = gnwrapper.Animation(cr.CarRacing(color = color))\n",
        "        self.env = cr.CarRacing(color = color)\n",
        "        self.color = color\n",
        "        self.env.seed(seed)\n",
        "        self.reward_threshold = 1000\n",
        "\n",
        "    def reset(self):\n",
        "        self.counter = 0\n",
        "        self.av_r = self.reward_memory()\n",
        "\n",
        "        self.die = False\n",
        "        img_rgb = self.env.reset()\n",
        "        img_rgb = img_rgb / 128. - 1\n",
        "        self.stack = [img_rgb] * 4\n",
        "        return np.array(self.stack)\n",
        "\n",
        "    def step(self, action):\n",
        "        total_reward = 0\n",
        "        for i in range(8):\n",
        "            img_rgb, reward, die, _ = self.env.step(action)\n",
        "\n",
        "            if die: reward += 100\n",
        "\n",
        "            if self.color == 'g' and np.mean(img_rgb[:, :, 1]) > 185.0:\n",
        "                  reward -= 0.05\n",
        "\n",
        "            total_reward += reward\n",
        "\n",
        "            done = True if self.av_r(reward) <= -0.1 else False\n",
        "            if done or die:\n",
        "                break\n",
        "\n",
        "        img_rgb = img_rgb / 128. - 1\n",
        "        self.stack.pop(0)\n",
        "        self.stack.append(img_rgb)\n",
        "        assert len(self.stack) == 4\n",
        "        return np.array(self.stack), total_reward, done, die\n",
        "\n",
        "    def step_eval(self, action):\n",
        "        img_rgb, reward, done, _ = self.env.step(action)\n",
        "\n",
        "        img_rgb = img_rgb / 128. - 1\n",
        "        self.stack.pop(0)\n",
        "        self.stack.append(img_rgb)\n",
        "        return np.array(self.stack), reward, done, _\n",
        "\n",
        "    def render(self, *arg):\n",
        "        self.env.render(*arg)\n",
        "\n",
        "    @staticmethod\n",
        "    def reward_memory():\n",
        "        count = 0\n",
        "        length = 100\n",
        "        history = np.zeros(length)\n",
        "\n",
        "        def memory(reward):\n",
        "            nonlocal count\n",
        "            history[count] = reward\n",
        "            count = (count + 1) % length\n",
        "            return np.mean(history)\n",
        "\n",
        "        return memory"
      ],
      "metadata": {
        "id": "1B-fDIj9j-md"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "env_green = gnwrapper.Animation(cr.CarRacing())\n",
        "env_green = cr.CarRacing(color = 'g')\n",
        "obs = env_green.reset()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I-siC4ODjgfl",
        "outputId": "dcba20ef-5048-423c-bf53-2e13a40768b4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gym/spaces/box.py:74: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
            "  \"Box bound precision lowered by casting to {}\".format(self.dtype)\n",
            "/usr/local/lib/python3.7/dist-packages/gym/spaces/box.py:74: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
            "  \"Box bound precision lowered by casting to {}\".format(self.dtype)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_random(state):\n",
        "    red_scale, green_scale, blue_scale = 1., 1., 1.\n",
        "    base_scale = 0.5\n",
        "    while (red_scale == green_scale == blue_scale):\n",
        "        add_green = random.randint(0, 1)\n",
        "        add_red = random.randint(0, 1)\n",
        "        add_blue = random.randint(0, 1)\n",
        "        if (add_red): \n",
        "            red_scale = random.uniform(0.5, 1.1)\n",
        "        if (add_green): \n",
        "            green_scale = random.uniform(0.5, 1.1)\n",
        "        if (add_blue): \n",
        "            blue_scale = random.uniform(0.5, 1.1)\n",
        "            \n",
        "    for i in range (0, 4):\n",
        "        s = torch.transpose(state[i], 0, 2)\n",
        "        road = s [1] - s [0] * 0.6 - s[2] * 0.4\n",
        "        road = torch.stack((road, road, road), 0)\n",
        "        ones = torch.ones(3, 96, 96).to(device)\n",
        "\n",
        "        road_mask = torch.logical_xor(road, ones)\n",
        "        road_layer = s * road_mask\n",
        "\n",
        "        light_green = 204 / 128. - 1\n",
        "        light_green_mask = torch.logical_xor(s - light_green , ones)\n",
        "        light_green_layer = s * light_green_mask\n",
        "\n",
        "        dark_green = 230 / 128. - 1\n",
        "        dark_green_mask = torch.logical_xor(s - dark_green , ones)\n",
        "        dark_green_layer = s * dark_green_mask\n",
        "\n",
        "        bg_layer = light_green_layer + dark_green_layer\n",
        "\n",
        "        ones = torch.ones(96, 96).to(device)\n",
        "        back_ground_mask = torch.logical_xor(bg_layer[1], ones)\n",
        "\n",
        "        red_channel = (back_ground_mask * 128) /128. - 1\n",
        "        green_channel = (back_ground_mask * 128) /128. - 1\n",
        "        blue_channel = (back_ground_mask * 128) /128. - 1\n",
        "\n",
        "        if (add_red): red_channel = bg_layer[1] * red_scale\n",
        "        if (add_green): green_channel = bg_layer[1] * green_scale\n",
        "        if (add_blue): blue_channel = bg_layer[1] * blue_scale\n",
        "\n",
        "        new_bg_layer = torch.stack((red_channel, green_channel, blue_channel), 0)\n",
        "\n",
        "        new_state = new_bg_layer + road_layer\n",
        "\n",
        "        state[i] = torch.transpose(new_state, 0, 2)\n",
        "        \n",
        "    return state  \n",
        "\n",
        "def get_random_buffer(buffer, batch_size):\n",
        "    target_buffer = buffer.clone()\n",
        "    for i in range (batch_size):\n",
        "        target_buffer[i] = get_random(target_buffer[i])\n",
        "    return target_buffer"
      ],
      "metadata": {
        "id": "GrD8UTgYXUg_"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DSN Model"
      ],
      "metadata": {
        "id": "FJO-x4UlkFSy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "wu8X2di_QtJD"
      },
      "outputs": [],
      "source": [
        "class ReverseLayerF(Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx, x, alpha):\n",
        "        ctx.alpha = alpha\n",
        "        return x.view_as(x)\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        output = grad_output.neg() * ctx.alpha\n",
        "        return output, None  \n",
        "\n",
        "class DSN(nn.Module):\n",
        "    def __init__(self, num_out = 2):\n",
        "        super(DSN, self).__init__()\n",
        "        \n",
        "        self.sketch = nn.Sequential(\n",
        "            nn.Conv3d(4, 4, kernel_size=(1, 1, 3), stride=1),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "        self.source_encoder = nn.Sequential(\n",
        "            nn.Conv2d(4, 8, kernel_size=4, stride=2),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(8, 16, kernel_size=3, stride=2),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(16, 32, kernel_size=3, stride=2),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32, 64, kernel_size=3, stride=2),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "        \n",
        "        self.target_encoder = nn.Sequential(\n",
        "            nn.Conv2d(4, 8, kernel_size=4, stride=2),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(8, 16, kernel_size=3, stride=2),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(16, 32, kernel_size=3, stride=2),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32, 64, kernel_size=3, stride=2),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "        \n",
        "        self.shared_encoder = nn.Sequential(\n",
        "            nn.Conv2d(4, 8, kernel_size=4, stride=2),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(8, 16, kernel_size=3, stride=2),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(16, 32, kernel_size=3, stride=2),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32, 48, kernel_size=3, stride=2),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "\n",
        "        self.source_fc = nn.Sequential(\n",
        "            nn.Linear(in_features = 64 * 5 * 5, out_features = 512),\n",
        "            nn.ReLU(True)\n",
        "            )\n",
        "        \n",
        "        self.target_fc = nn.Sequential(\n",
        "            nn.Linear(in_features = 64 * 5 * 5, out_features=512),\n",
        "            nn.ReLU(True)\n",
        "            )\n",
        "        \n",
        "        self.shared_fc = nn.Sequential(\n",
        "            nn.Linear(in_features= 48 * 5 * 5, out_features=512),\n",
        "            nn.ReLU(True)\n",
        "            )\n",
        "        \n",
        "        self.pred_domain = nn.Sequential(\n",
        "            nn.Linear(in_features=512, out_features=128),\n",
        "            nn.ReLU(True),\n",
        "            nn.Linear(in_features=128, out_features=2)\n",
        "        )\n",
        "\n",
        "        self.shared_decoder_fc = nn.Sequential(nn.Linear(in_features=512, out_features=64 * 5 * 5))\n",
        "\n",
        "        self.shared_decoder_conv = nn.Sequential(\n",
        "            nn.ConvTranspose2d(64, 32, 3, stride=2),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(32, 16, 3, stride=2),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(16, 8, 3, stride=2),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(8, 4, 4, stride=2),\n",
        "            nn.ReLU(True),\n",
        "        )\n",
        "        self.v = nn.Sequential(nn.Linear(512, 100), nn.ReLU(), nn.Linear(100, 1))\n",
        "        self.fc = nn.Sequential(nn.Linear(512, 100), nn.ReLU())\n",
        "        self.alpha_head = nn.Sequential(nn.Linear(100, 3), nn.Softplus())\n",
        "        self.beta_head = nn.Sequential(nn.Linear(100, 3), nn.Softplus())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loss Functions"
      ],
      "metadata": {
        "id": "Sx66s0bPkHl2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MSE(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MSE, self).__init__()\n",
        "\n",
        "    def forward(self, pred, real):\n",
        "        diffs = torch.add(real, -pred)\n",
        "        n = torch.numel(diffs.data)\n",
        "        mse = torch.sum(diffs.pow(2)) / n\n",
        "\n",
        "        return mse\n",
        "\n",
        "\n",
        "class SIMSE(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(SIMSE, self).__init__()\n",
        "\n",
        "    def forward(self, pred, real):\n",
        "        diffs = torch.add(real, - pred)\n",
        "        n = torch.numel(diffs.data)\n",
        "        simse = torch.sum(diffs).pow(2) / (n ** 2)\n",
        "\n",
        "        return simse\n",
        "\n",
        "\n",
        "class DiffLoss(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(DiffLoss, self).__init__()\n",
        "\n",
        "    def forward(self, input1, input2):\n",
        "\n",
        "        batch_size = input1.size(0)\n",
        "        input1 = input1.view(batch_size, -1)\n",
        "        input2 = input2.view(batch_size, -1)\n",
        "\n",
        "        input1_l2_norm = torch.norm(input1, p=2, dim=1, keepdim=True).detach()\n",
        "        input1_l2 = input1.div(input1_l2_norm.expand_as(input1) + 1e-6)\n",
        "\n",
        "        input2_l2_norm = torch.norm(input2, p=2, dim=1, keepdim=True).detach()\n",
        "        input2_l2 = input2.div(input2_l2_norm.expand_as(input2) + 1e-6)\n",
        "\n",
        "        diff_loss = torch.mean((input1_l2.t().mm(input2_l2)).pow(2))\n",
        "\n",
        "        return diff_loss"
      ],
      "metadata": {
        "id": "1CyEmCTSNYI2"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_classification = torch.nn.CrossEntropyLoss()\n",
        "loss_recon1 = MSE()\n",
        "loss_recon2 = SIMSE()\n",
        "loss_diff = DiffLoss()\n",
        "loss_similarity = torch.nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "QI-AjVukNCG5"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Agent"
      ],
      "metadata": {
        "id": "ZXct1Z4bkKPX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Agent():\n",
        "    max_grad_norm = 0.5\n",
        "    clip_param = 0.1\n",
        "    ppo_epoch = 10\n",
        "    alpha_weight = 0.01\n",
        "    beta_weight = 0.075\n",
        "    gamma_weight = 0.25\n",
        "\n",
        "    transition = np.dtype([('s', np.float64, (4, 96, 96, 3)), ('a', np.float64, (3,)), ('a_logp', np.float64),\n",
        "                       ('r', np.float64), ('s_', np.float64, (4, 96, 96, 3))])\n",
        "    \n",
        "    def __init__(self, net, criterion, optimizer, buffer_capacity = 2000, batch_size = 128):\n",
        "        self.net = net\n",
        "        self.buffer_capacity = buffer_capacity\n",
        "        self.batch_size = batch_size\n",
        "        self.criterion = criterion\n",
        "        self.optimizer = optimizer\n",
        "\n",
        "        self.source_buffer = np.empty(self.buffer_capacity, dtype=self.transition)\n",
        "        self.counter = 0\n",
        "\n",
        "    def select_action(self, state):\n",
        "        state = torch.from_numpy(state).double().to(device).unsqueeze(0)\n",
        "        with torch.no_grad():\n",
        "            sketch = self.net.sketch(state)\n",
        "            sketch = torch.squeeze(sketch)\n",
        "            source_encode = self.net.source_encoder(sketch)\n",
        "            source_encode = source_encode.view(-1, 64 * 5 * 5)\n",
        "            private_code = self.net.source_fc(source_encode)\n",
        "\n",
        "            shared_encode = self.net.shared_encoder(sketch)\n",
        "            shared_encode = shared_encode.view(-1, 48 * 5 * 5)\n",
        "            shared_code = self.net.shared_fc(shared_encode)\n",
        "\n",
        "            out = self.net.fc(shared_code)\n",
        "\n",
        "            alpha = self.net.alpha_head(out) + 1\n",
        "            beta = self.net.beta_head(out) + 1\n",
        "\n",
        "        dist = Beta(alpha, beta)\n",
        "        action = dist.sample()\n",
        "        a_logp = dist.log_prob(action).sum(dim=1)\n",
        "\n",
        "        action = action.squeeze().cpu().numpy()\n",
        "        a_logp = a_logp.item()\n",
        "        return action, a_logp\n",
        "\n",
        "    def store(self, transition):\n",
        "        self.source_buffer[self.counter] = transition\n",
        "        self.counter += 1\n",
        "        if self.counter == self.buffer_capacity:\n",
        "            self.counter = 0\n",
        "            return True\n",
        "\n",
        "        return False\n",
        "\n",
        "    def update(self, epoch, eta = 0.1):\n",
        "        s = torch.tensor(self.source_buffer['s'], dtype=torch.double).to(device)\n",
        "        a = torch.tensor(self.source_buffer['a'], dtype=torch.double).to(device)\n",
        "        r = torch.tensor(self.source_buffer['r'], dtype=torch.double).to(device).view(-1, 1)\n",
        "        s_ = torch.tensor(self.source_buffer['s_'], dtype=torch.double).to(device)\n",
        "        old_a_logp = torch.tensor(self.source_buffer['a_logp'], dtype=torch.double).to(device).view(-1, 1)\n",
        "\n",
        "        source_domain_label = torch.zeros(self.batch_size).long()\n",
        "        target_domain_label = torch.ones(self.batch_size).long()\n",
        "        source_domain_label = source_domain_label.to(device)\n",
        "        target_domain_label = target_domain_label.to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            sketch = self.net.sketch(s_)\n",
        "            sketch = torch.squeeze(sketch)\n",
        "\n",
        "            source_encode = self.net.source_encoder(sketch)\n",
        "            source_encode = source_encode.view(-1, 64 * 5 * 5)\n",
        "            private_code = self.net.source_fc(source_encode)\n",
        "\n",
        "            shared_encode = self.net.shared_encoder(sketch)\n",
        "            shared_encode = shared_encode.view(-1, 48 * 5 * 5)\n",
        "            shared_code = self.net.shared_fc(shared_encode)\n",
        "            target_v = self.net.v(shared_code)\n",
        "            \n",
        "            sketch = self.net.sketch(s)\n",
        "            sketch = torch.squeeze(sketch)\n",
        "\n",
        "            source_encode = self.net.source_encoder(sketch)\n",
        "            source_encode = source_encode.view(-1, 64 * 5 * 5)\n",
        "            private_code = self.net.source_fc(source_encode)\n",
        "\n",
        "            shared_encode = self.net.shared_encoder(sketch)\n",
        "            shared_encode = shared_encode.view(-1, 48 * 5 * 5)\n",
        "            shared_code = self.net.shared_fc(shared_encode)\n",
        "            adv = target_v - self.net.v(shared_code)\n",
        "\n",
        "        image_array = []\n",
        "        source_acc_array, target_acc_array = [], []\n",
        "        source_similarity_loss, target_similarity_loss = [], []\n",
        "        source_diff_loss, target_diff_loss = [], []\n",
        "        source_recon_loss1, target_recon_loss1 = [], []\n",
        "        source_recon_loss2, target_recon_loss2 = [], []\n",
        "        ppo_loss = []\n",
        "\n",
        "        for _ in range(self.ppo_epoch):\n",
        "            total = 0\n",
        "            source_domain_correct, target_domain_correct = 0, 0\n",
        "            add_image = True\n",
        "            \n",
        "            for index in BatchSampler(SubsetRandomSampler(range(self.buffer_capacity)), self.batch_size, True):\n",
        "                total += self.batch_size\n",
        "                # Source\n",
        "                sketch = self.net.sketch(s[index])\n",
        "                sketch = torch.squeeze(sketch)\n",
        "\n",
        "                source_encode = self.net.source_encoder(sketch)\n",
        "                source_encode = source_encode.view(-1, 64 * 5 * 5)\n",
        "                private_code = self.net.source_fc(source_encode)\n",
        "\n",
        "                shared_encode = self.net.shared_encoder(sketch)\n",
        "                shared_encode = shared_encode.view(-1, 48 * 5 * 5)\n",
        "                shared_code = self.net.shared_fc(shared_encode)\n",
        "\n",
        "                # PPO update\n",
        "                v = self.net.v(shared_code)\n",
        "                out = self.net.fc(shared_code)\n",
        "                alpha = self.net.alpha_head(out) + 1\n",
        "                beta = self.net.beta_head(out) + 1\n",
        "                dist = Beta(alpha, beta)\n",
        "                a_logp = dist.log_prob(a[index]).sum(dim=1, keepdim=True)\n",
        "                ratio = torch.exp(a_logp - old_a_logp[index])\n",
        "                surr1 = ratio * adv[index]\n",
        "                surr2 = torch.clamp(ratio, 1.0 - self.clip_param, 1.0 + self.clip_param) * adv[index]\n",
        "\n",
        "                # Domain classifier update\n",
        "                reversed_shared_code = ReverseLayerF.apply(shared_code, eta)\n",
        "                domain_label = self.net.pred_domain(reversed_shared_code)\n",
        "                _, predicted = torch.max(domain_label.data, 1)\n",
        "                source_domain_correct += predicted.eq(source_domain_label.data).cpu().sum().item()\n",
        "\n",
        "                # Decoder\n",
        "                rec_vec = self.net.shared_decoder_fc(private_code + shared_code)\n",
        "                rec_vec = rec_vec.view(-1, 64, 5, 5)\n",
        "                rec_code_s = self.net.shared_decoder_conv(rec_vec)\n",
        "\n",
        "                # Loss\n",
        "                action_loss = -torch.min(surr1, surr2).mean()\n",
        "                value_loss = F.smooth_l1_loss(v, target_v[index])\n",
        "                similarity_loss = self.gamma_weight * loss_similarity(domain_label, source_domain_label)\n",
        "                diff_loss = self.beta_weight * loss_diff(private_code, shared_code)\n",
        "                recon_loss_1 = self.alpha_weight * loss_recon1(rec_code_s, sketch)\n",
        "                recon_loss_2 = self.alpha_weight * loss_recon2(rec_code_s, sketch)\n",
        "\n",
        "                source_similarity_loss.append(similarity_loss)\n",
        "                source_diff_loss.append(diff_loss)\n",
        "                source_recon_loss1.append(recon_loss_1)\n",
        "                source_recon_loss2.append(recon_loss_2)\n",
        "                ppo_loss.append(action_loss + 2. * value_loss)\n",
        "\n",
        "                loss = action_loss + 2. * value_loss + similarity_loss + diff_loss + recon_loss_1 + recon_loss_2\n",
        "                print(loss)\n",
        "                self.net.zero_grad()\n",
        "                loss.backward()\n",
        "                self.optimizer.step()\n",
        "\n",
        "                # Target\n",
        "                with torch.no_grad():\n",
        "                    target_batch = get_random_buffer(s[index], self.batch_size)\n",
        "                sketch = self.net.sketch(target_batch)\n",
        "                sketch  = torch.squeeze(sketch)\n",
        "\n",
        "                target_encode = self.net.target_encoder(sketch)\n",
        "                target_encode = target_encode.view(-1, 64 * 5 * 5)\n",
        "                private_code = self.net.target_fc(target_encode)\n",
        "\n",
        "                shared_encode = self.net.shared_encoder(sketch)\n",
        "                shared_encode = shared_encode.view(-1, 48 * 5 * 5)\n",
        "                shared_code = self.net.shared_fc(shared_encode)\n",
        "\n",
        "                # Domain classifier update\n",
        "                reversed_shared_code = ReverseLayerF.apply(shared_code, eta)\n",
        "                domain_label = self.net.pred_domain(reversed_shared_code)\n",
        "                _, predicted = torch.max(domain_label.data, 1)\n",
        "                target_domain_correct += predicted.eq(target_domain_label.data).cpu().sum().item()\n",
        "\n",
        "                # Decoder\n",
        "                rec_vec = self.net.shared_decoder_fc(private_code + shared_code)\n",
        "                rec_vec = rec_vec.view(-1, 64, 5, 5)\n",
        "                rec_code_t = self.net.shared_decoder_conv(rec_vec)\n",
        "\n",
        "                # Loss\n",
        "                similarity_loss = self.gamma_weight * loss_similarity(domain_label, target_domain_label)\n",
        "                diff_loss = self.beta_weight * loss_diff(private_code, shared_code)\n",
        "                recon_loss_1 = self.alpha_weight * loss_recon1(rec_code_t, sketch)\n",
        "                recon_loss_2 = self.alpha_weight * loss_recon2(rec_code_t, sketch)\n",
        "\n",
        "                target_similarity_loss.append(similarity_loss)\n",
        "                target_diff_loss.append(diff_loss)\n",
        "                target_recon_loss1.append(recon_loss_1)\n",
        "                target_recon_loss2.append(recon_loss_2)\n",
        "\n",
        "                loss = similarity_loss + diff_loss + recon_loss_1 + recon_loss_2\n",
        "                self.net.zero_grad()\n",
        "                loss.backward()\n",
        "                self.optimizer.step()\n",
        "\n",
        "                if (add_image):\n",
        "                    image = rec_code_s[0][0].reshape(96, 96)\n",
        "                    image = image.cpu().detach().numpy()\n",
        "                    image_array.append(image)\n",
        "                \n",
        "                    image = rec_code_t[0][0].reshape(96, 96)\n",
        "                    image = image.cpu().detach().numpy()\n",
        "                    image_array.append(image)\n",
        "                    \n",
        "                    add_image = False\n",
        "\n",
        "            source_acc_array.append( source_domain_correct / total )\n",
        "            target_acc_array.append( target_domain_correct / total )\n",
        "        \n",
        "        '''\n",
        "        print(\"Source acc\", end = ' ')\n",
        "        print(source_acc_array)\n",
        "        print(\"Target acc\", end = ' ')\n",
        "        print(target_acc_array)\n",
        "        print(\"source_similarity_loss\", end = ' ')\n",
        "        print(source_similarity_loss)\n",
        "        print(\"target_similarity_loss\", end = ' ')\n",
        "        print(target_similarity_loss)\n",
        "        print(\"source_diff_loss\", end = ' ')\n",
        "        print(source_diff_loss)\n",
        "        print(\"target_diff_loss\", end = ' ')\n",
        "        print(target_diff_loss)\n",
        "        print(\"source_recon_loss1\", end = ' ')\n",
        "        print(source_recon_loss1)\n",
        "        print(\"target_recon_loss1\", end = ' ')\n",
        "        print(target_recon_loss1)\n",
        "        print(\"source_recon_loss2\", end = ' ')\n",
        "        print(source_recon_loss2)\n",
        "        print(\"target_recon_loss2\", end = ' ')\n",
        "        print(target_recon_loss2)\n",
        "        '''\n",
        "\n",
        "        source_acc_mean, target_acc_mean = 0, 0\n",
        "        for acc in source_acc_array: source_acc_mean += acc\n",
        "        for acc in target_acc_array: target_acc_mean += acc\n",
        "            \n",
        "        f, axs = plt.subplots(2, 10, figsize = (16, 4))\n",
        "        axs = axs.flatten()\n",
        "        for img, ax in zip(image_array, axs):\n",
        "            ax.imshow(img)\n",
        "        f.savefig('./output_r/%04d.png' % epoch)\n",
        "        plt.close(f)\n",
        "        \n",
        "        return source_acc_mean / 10 , target_acc_mean / 10"
      ],
      "metadata": {
        "id": "n5cceWCtXDy0"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Agent Trainig"
      ],
      "metadata": {
        "id": "PDML5gaIkeYn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def eval(agent, env):\n",
        "    score = 0\n",
        "    state = env.reset()\n",
        "\n",
        "    for t in range(1000):\n",
        "        action, a_logp = agent.select_action(state)\n",
        "\n",
        "        state_, reward, done, _ = env.step_eval(action * np.array([2., 1., 1.]) + np.array([-1., 0., 0.]))\n",
        "\n",
        "        score += reward\n",
        "\n",
        "        state = state_\n",
        "\n",
        "        if done:\n",
        "            break\n",
        "\n",
        "    return score"
      ],
      "metadata": {
        "id": "5nbd6qsQkP51"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(source_env, target_env, agent):\n",
        "    training_records= []\n",
        "    running_score_records = []\n",
        "    running_score = 0\n",
        "    \n",
        "    c1_running_score = 0\n",
        "    c1_training_records = []\n",
        "    c1_running_score_records = []\n",
        "    \n",
        "    c2_running_score = 0\n",
        "    c2_training_records = []\n",
        "    c2_running_score_records = []\n",
        "    \n",
        "    eta = 0.1\n",
        "    for i_ep in range(3000):\n",
        "        score = 0\n",
        "        state = source_env.reset()\n",
        "\n",
        "        for t in range(1000):\n",
        "            action, a_logp = agent.select_action(state)\n",
        "            state_, reward, done, die = source_env.step(action * np.array([2., 1., 1.])\\\n",
        "                                                                       + np.array([-1., 0., 0.]))\n",
        "            score += reward\n",
        "\n",
        "            should_update = agent.store((state, action, a_logp, reward, state_))\n",
        "\n",
        "            if should_update: \n",
        "                if (i_ep < 500): eta_max =  1.0\n",
        "                elif (i_ep < 1500): eta_max = 0.9\n",
        "                else: eta_max = 0.7\n",
        "                    \n",
        "                print(\"eta: %.2f\" % eta)\n",
        "                s_acc, t_acc = agent.update(epoch = i_ep, eta = eta) \n",
        "                \n",
        "            state = state_\n",
        "\n",
        "            if done or die: break\n",
        "                \n",
        "        training_records.append(score)\n",
        "        running_score = running_score * 0.99 + score * 0.01\n",
        "        running_score_records.append(running_score)\n",
        "        \n",
        "        c1_score = eval(agent, target_env[0])\n",
        "        c2_score = eval(agent, target_env[1])\n",
        "        c1_training_records.append(c1_score)\n",
        "        c2_training_records.append(c2_score)\n",
        "        \n",
        "        c1_running_score = c1_running_score * 0.99 + c1_score * 0.01\n",
        "        c2_running_score = c2_running_score * 0.99 + c2_score * 0.01\n",
        "        c1_running_score_records.append(c1_running_score)\n",
        "        c2_running_score_records.append(c2_running_score)\n",
        "        \n",
        "        if (i_ep % 10 == 0):\n",
        "            print('Ep {}\\tLast score: {:.2f}\\tMoving average score: {:.2f}'.format(i_ep, score, running_score))\n",
        "            print('c1 score: {:.2f}\\t c1 Moving average: {:.2f}'.format(c1_score, c1_running_score))\n",
        "            print('c2 score: {:.2f}\\t c2 Moving average: {:.2f}'.format(c2_score, c2_running_score))\n",
        "            \n",
        "            if (i_ep != 0):\n",
        "                f, axs = plt.subplots(1, 2, figsize = (16, 8))\n",
        "                axs[0].plot(range(len(training_records)), training_records)\n",
        "                axs[1].plot(range(len(running_score_records)), running_score_records)\n",
        "                axs[0].plot(range(len(c1_training_records)), c1_training_records)\n",
        "                axs[1].plot(range(len(c1_running_score_records)), c1_running_score_records)\n",
        "                axs[0].plot(range(len(c2_training_records)), c2_training_records)\n",
        "                axs[1].plot(range(len(c2_running_score_records)), c2_running_score_records)\n",
        "                axs[0].legend(['s', 'c1', 'c2'])\n",
        "                axs[1].legend(['s', 'c1', 'c2'])\n",
        "\n",
        "                f.savefig('./output_r/result_%04d.png' % i_ep)\n",
        "                plt.close(f)\n"
      ],
      "metadata": {
        "id": "dG8TknrYkXG2"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "green_env = Env(color = 'g', seed = 0)\n",
        "env_c1 = Env(color = 'c1', seed = 0)\n",
        "env_c2 = Env(color = 'c2', seed = 0)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss().cuda()\n",
        "net = DSN().double().cuda()\n",
        "optimizer = optim.Adam(net.parameters(), lr=1e-3)\n",
        "agent = Agent(net = net,  criterion = criterion,  optimizer = optimizer, buffer_capacity = 2048, batch_size = 128)\n",
        "\n",
        "source_env = green_env\n",
        "target_env = [env_c1, env_c2]\n",
        "train(green_env, target_env, agent)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hyCpJ2RhkaX1",
        "outputId": "145f5607-1e39-48df-c1f1-73ccdbb8013a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gym/spaces/box.py:74: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
            "  \"Box bound precision lowered by casting to {}\".format(self.dtype)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 0\tLast score: -17.84\tMoving average score: -0.18\n",
            "c1 score: -19.46\t c1 Moving average: -0.19\n",
            "c2 score: -19.46\t c2 Moving average: -0.19\n",
            "retry to generate track (normal if there are not manyinstances of this message)\n",
            "retry to generate track (normal if there are not manyinstances of this message)\n",
            "retry to generate track (normal if there are not manyinstances of this message)\n",
            "Ep 10\tLast score: -17.99\tMoving average score: -1.58\n",
            "c1 score: -9.45\t c1 Moving average: -2.52\n",
            "c2 score: -9.45\t c2 Moving average: -2.52\n",
            "retry to generate track (normal if there are not manyinstances of this message)\n",
            "retry to generate track (normal if there are not manyinstances of this message)\n",
            "retry to generate track (normal if there are not manyinstances of this message)\n",
            "eta: 0.10\n",
            "tensor(0.2026, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(0.2010, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(0.2000, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(0.1958, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(0.1955, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(0.1953, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(0.1950, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(0.1947, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(0.1945, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(0.1943, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(0.1941, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(0.1939, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(0.1938, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(0.1936, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(0.1934, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(0.1932, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(0.1931, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(0.1929, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(0.1928, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(0.1926, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(0.1924, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(0.1922, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(0.1921, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(0.1919, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(0.1918, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(0.1916, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(0.1915, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(0.1913, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(0.1912, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(0.1910, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(0.1909, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(0.1908, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(0.1906, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(0.1905, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(0.1904, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(0.1902, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(0.1901, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(0.1900, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(0.1899, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(0.1898, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(0.1896, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(0.1895, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(0.1894, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(0.1893, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(0.1892, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(0.1891, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(0.1890, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(0.1888, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(0.1887, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(0.1886, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(0.1885, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(0.1884, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(0.1883, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(0.1882, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(0.1881, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(0.1880, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(0.1879, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(0.1878, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(0.1877, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(0.1876, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(0.1874, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(0.1874, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(0.1873, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(0.1872, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(0.1871, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(0.1870, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(0.1869, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(0.1868, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(0.1867, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(0.1866, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(0.1865, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(0.1864, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(0.1863, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(0.1862, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(0.1861, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(0.1860, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(0.1860, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(0.1859, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(0.1858, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(0.1857, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(0.1856, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(0.1855, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(0.1854, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(0.1853, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(0.1852, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(0.1852, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(0.1851, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(0.1850, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(0.1849, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(0.1848, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(0.1847, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(0.1847, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(0.1846, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(0.1845, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(0.1844, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(0.1843, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(0.1843, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(0.1842, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(0.1841, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(0.1840, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(0.1839, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(0.1839, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(0.1838, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(0.1837, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(0.1836, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(0.1836, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(0.1835, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(0.1834, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(0.1834, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(0.1833, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(0.1832, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(0.1831, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(0.1831, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(0.1830, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(0.1829, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(0.1829, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(0.1828, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(0.1827, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(0.1826, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(0.1826, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(0.1825, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(0.1824, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(0.1824, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(0.1823, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(0.1822, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(0.1822, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(0.1821, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(0.1820, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(0.1820, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(0.1819, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(0.1819, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(0.1818, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(0.1817, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(0.1817, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(0.1816, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(0.1815, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(0.1815, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(0.1814, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(0.1813, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(0.1813, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(0.1812, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(0.1812, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(0.1811, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(0.1811, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(0.1810, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(0.1809, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(0.1809, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(0.1808, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(0.1808, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(0.1807, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(0.1806, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(0.1806, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(0.1806, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(0.1805, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(0.1805, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(0.1804, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor(0.1803, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.10.6 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.6"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
      }
    },
    "colab": {
      "provenance": [],
      "name": "“dsn.ipynb”的副本",
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}