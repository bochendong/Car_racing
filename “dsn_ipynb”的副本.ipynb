{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bochendong/car_racing/blob/main/%E2%80%9Cdsn_ipynb%E2%80%9D%E7%9A%84%E5%89%AF%E6%9C%AC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Global Enviorment Settings"
      ],
      "metadata": {
        "id": "sXw-vOXxju2p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/bochendong/car_racing.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kyiqjBTljuBC",
        "outputId": "31289e9f-3f19-4348-e220-7ffd1daa1df7"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'car_racing'...\n",
            "remote: Enumerating objects: 127, done.\u001b[K\n",
            "remote: Counting objects: 100% (127/127), done.\u001b[K\n",
            "remote: Compressing objects: 100% (106/106), done.\u001b[K\n",
            "remote: Total 127 (delta 69), reused 40 (delta 16), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (127/127), 1.15 MiB | 11.01 MiB/s, done.\n",
            "Resolving deltas: 100% (69/69), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!sudo apt update && sudo apt install python-opengl\n",
        "!sudo apt update && sudo apt install xvfb\n",
        "!pip install gym-notebook-wrapper stable-baselines[mpi] box2d box2d-kengz pyvirtualdisplay pyglet\n",
        "!pip install wandb\n",
        "!pip install gym==0.21.0\n",
        "!pip install pyvirtualdisplay -qq\n",
        "!pip install folium==0.2.1\n",
        "!apt-get install -y xvfb python-opengl ffmpeg -qq\n",
        "!pip install box2d"
      ],
      "metadata": {
        "id": "6dYb1D3hjzdc"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import random\n",
        "\n",
        "from PIL import Image\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import namedtuple\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as T\n",
        "import torch.optim as optim\n",
        "from torch.distributions import Beta\n",
        "from torch.utils.data.sampler import BatchSampler, SubsetRandomSampler\n",
        "\n",
        "from torch.autograd import Function\n",
        "\n",
        "import gnwrapper\n",
        "import gym\n",
        "from gym import logger as gymlogger\n",
        "gymlogger.set_level(30)\n",
        "\n",
        "from IPython.display import HTML\n",
        "from IPython import display as ipythondisplay\n",
        "from pyvirtualdisplay import Display\n",
        "import wandb\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import glob"
      ],
      "metadata": {
        "id": "zJDwIbQ9jry6"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd car_racing\n",
        "import car_racing as cr"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AqLJJUhAjoH7",
        "outputId": "70863509-2680-4d9d-cf9a-4a49c8c31f17"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/car_racing\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "print(device)\n",
        "\n",
        "if (os.path.exists(\"./output_r\")) == False:\n",
        "    os.mkdir(\"output_r\")\n",
        "    \n",
        "for epoch in range (3000):\n",
        "    files = glob.glob(\"./output_r/*.png\")\n",
        "\n",
        "    for f in files:\n",
        "        os.remove(f)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H6TQ87Bkjkzz",
        "outputId": "2d1da62b-ee73-4303-9c54-9c98da9f8cc8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Car Racing Env Wrapper"
      ],
      "metadata": {
        "id": "w676toodj6G1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Env():\n",
        "    def __init__(self, color, seed = 0):\n",
        "        self.env = gnwrapper.Animation(cr.CarRacing(color = color))\n",
        "        self.env = cr.CarRacing(color = color)\n",
        "        self.color = color\n",
        "        self.env.seed(seed)\n",
        "        self.reward_threshold = 1000\n",
        "\n",
        "    def reset(self):\n",
        "        self.counter = 0\n",
        "        self.av_r = self.reward_memory()\n",
        "\n",
        "        self.die = False\n",
        "        img_rgb = self.env.reset()\n",
        "        img_rgb = img_rgb / 128. - 1\n",
        "        self.stack = [img_rgb] * 4\n",
        "        return np.array(self.stack)\n",
        "\n",
        "    def step(self, action):\n",
        "        total_reward = 0\n",
        "        for i in range(8):\n",
        "            img_rgb, reward, die, _ = self.env.step(action)\n",
        "\n",
        "            if die: reward += 100\n",
        "\n",
        "            if self.color == 'g' and np.mean(img_rgb[:, :, 1]) > 185.0:\n",
        "                  reward -= 0.05\n",
        "\n",
        "            total_reward += reward\n",
        "\n",
        "            done = True if self.av_r(reward) <= -0.1 else False\n",
        "            if done or die:\n",
        "                break\n",
        "\n",
        "        img_rgb = img_rgb / 128. - 1\n",
        "        self.stack.pop(0)\n",
        "        self.stack.append(img_rgb)\n",
        "        assert len(self.stack) == 4\n",
        "        return np.array(self.stack), total_reward, done, die\n",
        "\n",
        "    def step_eval(self, action):\n",
        "        img_rgb, reward, done, _ = self.env.step(action)\n",
        "\n",
        "        img_rgb = img_rgb / 128. - 1\n",
        "        self.stack.pop(0)\n",
        "        self.stack.append(img_rgb)\n",
        "        return np.array(self.stack), reward, done, _\n",
        "\n",
        "    def render(self, *arg):\n",
        "        self.env.render(*arg)\n",
        "\n",
        "    @staticmethod\n",
        "    def reward_memory():\n",
        "        count = 0\n",
        "        length = 100\n",
        "        history = np.zeros(length)\n",
        "\n",
        "        def memory(reward):\n",
        "            nonlocal count\n",
        "            history[count] = reward\n",
        "            count = (count + 1) % length\n",
        "            return np.mean(history)\n",
        "\n",
        "        return memory"
      ],
      "metadata": {
        "id": "1B-fDIj9j-md"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "env_green = gnwrapper.Animation(cr.CarRacing())\n",
        "env_green = cr.CarRacing(color = 'g')\n",
        "obs = env_green.reset()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I-siC4ODjgfl",
        "outputId": "c9aaff22-1a88-4548-9587-0364fb7f08cf"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gym/spaces/box.py:74: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
            "  \"Box bound precision lowered by casting to {}\".format(self.dtype)\n",
            "/usr/local/lib/python3.7/dist-packages/gym/spaces/box.py:74: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
            "  \"Box bound precision lowered by casting to {}\".format(self.dtype)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "red_block_0_0 = torch.zeros(3, 96, 96).to(device)\n",
        "red_block_0_1 = torch.zeros(3, 96, 96).to(device)\n",
        "for i in range(40, 60):\n",
        "    for j in range(40, 60):\n",
        "        red_block_0_0[0][i][j] = 1.\n",
        "        red_block_0_0[1][i][j] = 1.\n",
        "        red_block_0_0[2][i][j] = 1.\n",
        "\n",
        "for i in range(40, 60):\n",
        "    for j in range(40, 60):\n",
        "        red_block_0_1[0][i][j] = 1.\n",
        "        red_block_0_1[1][i][j] = -1.\n",
        "        red_block_0_1[2][i][j] = -1.\n",
        "\n",
        "red_block_1_0 = torch.zeros(3, 96, 96).to(device)\n",
        "red_block_1_1 = torch.zeros(3, 96, 96).to(device)\n",
        "\n",
        "for i in range(76, 96):\n",
        "    for j in range(0, 20):\n",
        "        red_block_1_0[0][i][j] = 1.\n",
        "        red_block_1_0[1][i][j] = 1.\n",
        "        red_block_1_0[2][i][j] = 1.\n",
        "\n",
        "for i in range(76, 96):\n",
        "    for j in range(0, 20):\n",
        "        red_block_1_1[0][i][j] = -1.\n",
        "        red_block_1_1[1][i][j] = 1.\n",
        "        red_block_1_1[2][i][j] = -1.\n",
        "\n",
        "red_block_2_0 = torch.zeros(3, 96, 96).to(device)\n",
        "red_block_2_1 = torch.zeros(3, 96, 96).to(device)\n",
        "for i in range(0, 20):\n",
        "    for j in range(0, 20):\n",
        "        red_block_2_0[0][i][j] = 1.\n",
        "        red_block_2_0[1][i][j] = 1.\n",
        "        red_block_2_0[2][i][j] = 1.\n",
        "\n",
        "for i in range(0, 20):\n",
        "    for j in range(0, 20):\n",
        "        red_block_2_1[0][i][j] = 1.\n",
        "        red_block_2_1[1][i][j] = -1.\n",
        "        red_block_2_1[2][i][j] = -1.\n",
        "\n",
        "red_block_3_0 = torch.zeros(3, 96, 96).to(device)\n",
        "red_block_3_1 = torch.zeros(3, 96, 96).to(device)\n",
        "for i in range(0, 20):\n",
        "    for j in range(64, 84):\n",
        "        red_block_3_0[0][i][j] = 1.\n",
        "        red_block_3_0[1][i][j] = 1.\n",
        "        red_block_3_0[2][i][j] = 1.\n",
        "\n",
        "for i in range(0, 20):\n",
        "    for j in range(64, 84):\n",
        "        red_block_3_1[0][i][j] = -1.\n",
        "        red_block_3_1[1][i][j] = 1.\n",
        "        red_block_3_1[2][i][j] = -1.  \n",
        "\n",
        "red_block_4_0 = torch.zeros(3, 96, 96).to(device)\n",
        "red_block_4_1 = torch.zeros(3, 96, 96).to(device)\n",
        "for i in range(76, 96):\n",
        "    for j in range(64, 84):\n",
        "        red_block_4_0[0][i][j] = 1.\n",
        "        red_block_4_0[1][i][j] = 1.\n",
        "        red_block_4_0[2][i][j] = 1.\n",
        "\n",
        "for i in range(76, 96):\n",
        "    for j in range(64, 84):\n",
        "        red_block_4_1[0][i][j] = 1.\n",
        "        red_block_4_1[1][i][j] = -1.\n",
        "        red_block_4_1[2][i][j] = -1.    \n",
        "\n",
        "red_block_array = [[red_block_0_0, red_block_0_1], [red_block_1_0, red_block_1_1], \n",
        "                   [red_block_2_0, red_block_2_1], [red_block_3_0, red_block_3_1], [red_block_4_0, red_block_4_1] ]"
      ],
      "metadata": {
        "id": "xqFnSF-W4DRi"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_random(state):\n",
        "    red_scale, green_scale, blue_scale = 1., 1., 1.\n",
        "    base_scale = 0.5\n",
        "    add_block = random.randint(0, 1)\n",
        "    while (red_scale == green_scale == blue_scale):\n",
        "        add_green = random.randint(0, 1)\n",
        "        add_red = random.randint(0, 1)\n",
        "        add_blue = random.randint(0, 1)\n",
        "        if (add_red): \n",
        "            red_scale = random.uniform(0.5, 1.1)\n",
        "        if (add_green): \n",
        "            green_scale = random.uniform(0.5, 1.1)\n",
        "        if (add_blue): \n",
        "            blue_scale = random.uniform(0.5, 1.1)\n",
        "            \n",
        "    for i in range (0, 4):\n",
        "        s = torch.transpose(state[i], 0, 2)\n",
        "        road = s [1] - s [0] * 0.6 - s[2] * 0.4\n",
        "        road = torch.stack((road, road, road), 0)\n",
        "        ones = torch.ones(3, 96, 96).to(device)\n",
        "\n",
        "        road_mask = torch.logical_xor(road, ones)\n",
        "        road_layer = s * road_mask\n",
        "\n",
        "        if (add_block):\n",
        "            red_block_type = random.randint(0, 4)\n",
        "            red_block_mask = red_block_array[red_block_type][0] * torch.logical_not(road_mask)\n",
        "            road_and_redblock_mask = torch.logical_xor(road_layer + red_block_mask, ones)\n",
        "            red_block_layer = red_block_array[red_block_type][1] * torch.logical_not(road_mask)\n",
        "\n",
        "            s = s * road_and_redblock_mask\n",
        "\n",
        "        light_green = 204 / 128. - 1\n",
        "        light_green_mask = torch.logical_xor(s - light_green , ones)\n",
        "        light_green_layer = s * light_green_mask\n",
        "\n",
        "        dark_green = 230 / 128. - 1\n",
        "        dark_green_mask = torch.logical_xor(s - dark_green , ones)\n",
        "        dark_green_layer = s * dark_green_mask\n",
        "\n",
        "        bg_layer = light_green_layer + dark_green_layer\n",
        "\n",
        "        ones = torch.ones(96, 96).to(device)\n",
        "\n",
        "        back_ground_mask = torch.logical_xor(bg_layer[1], ones)\n",
        "        red_channel = (back_ground_mask * 128) /128. - 1\n",
        "        green_channel = (back_ground_mask * 128) /128. - 1\n",
        "        blue_channel = (back_ground_mask * 128) /128. - 1\n",
        "\n",
        "        if (add_red): red_channel = bg_layer[1] * red_scale\n",
        "        if (add_green): green_channel = bg_layer[1] * green_scale\n",
        "        if (add_blue): blue_channel = bg_layer[1] * blue_scale\n",
        "\n",
        "        new_bg_layer = torch.stack((red_channel, green_channel, blue_channel), 0)\n",
        "\n",
        "        if (add_block):\n",
        "            new_state = new_bg_layer + road_layer + red_block_layer\n",
        "        else:\n",
        "            new_state = new_bg_layer + road_layer\n",
        "\n",
        "        state[i] = torch.transpose(new_state, 0, 2)\n",
        "        \n",
        "    return state \n",
        "\n",
        "def get_random_buffer(buffer, batch_size):\n",
        "    target_buffer = buffer.clone()\n",
        "    for i in range (batch_size):\n",
        "        target_buffer[i] = get_random(target_buffer[i])\n",
        "    return target_buffer"
      ],
      "metadata": {
        "id": "GrD8UTgYXUg_"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DSN Model"
      ],
      "metadata": {
        "id": "FJO-x4UlkFSy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "wu8X2di_QtJD"
      },
      "outputs": [],
      "source": [
        "class ReverseLayerF(Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx, x, alpha):\n",
        "        ctx.alpha = alpha\n",
        "        return x.view_as(x)\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        output = grad_output.neg() * ctx.alpha\n",
        "        return output, None  \n",
        "\n",
        "class DSN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(DSN, self).__init__()\n",
        "        \n",
        "        self.sketch = nn.Sequential(\n",
        "            nn.Conv3d(4, 4, kernel_size=(1, 1, 3), stride=1),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "\n",
        "        self.source_encoder = nn.Sequential(\n",
        "            nn.Conv2d(4, 8, kernel_size=4, stride=2),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(8, 16, kernel_size=3, stride=2),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(16, 32, kernel_size=3, stride=2),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32, 64, kernel_size=3, stride=2),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "        \n",
        "        self.target_encoder = nn.Sequential(\n",
        "            nn.Conv2d(4, 8, kernel_size=4, stride=2),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(8, 16, kernel_size=3, stride=2),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(16, 32, kernel_size=3, stride=2),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32, 64, kernel_size=3, stride=2),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "\n",
        "        self.shared_encoder = nn.Sequential(\n",
        "            nn.Conv2d(4, 8, kernel_size=4, stride=2),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(8, 16, kernel_size=3, stride=2),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(16, 32, kernel_size=3, stride=2),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32, 48, kernel_size=3, stride=2),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "\n",
        "        self.source_fc = nn.Sequential(\n",
        "            nn.Linear(in_features = 64 * 5 * 5, out_features = 512),\n",
        "            nn.ReLU(True)\n",
        "            )\n",
        "        \n",
        "        self.target_fc = nn.Sequential(\n",
        "            nn.Linear(in_features = 64 * 5 * 5, out_features=512),\n",
        "            nn.ReLU(True)\n",
        "            )\n",
        "        \n",
        "        self.shared_fc = nn.Sequential(\n",
        "            nn.Linear(in_features= 48 * 5 * 5, out_features=512),\n",
        "            nn.ReLU(True)\n",
        "            )\n",
        "        \n",
        "        self.pred_domain = nn.Sequential(\n",
        "            nn.Linear(in_features=512, out_features=128),\n",
        "            nn.ReLU(True),\n",
        "            nn.Linear(in_features=128, out_features=2)\n",
        "        )\n",
        "        self.shared_decoder_fc = nn.Sequential(nn.Linear(in_features=512, out_features=64 * 5 * 5))\n",
        "\n",
        "        self.shared_decoder_conv = nn.Sequential(\n",
        "            nn.ConvTranspose2d(64, 32, 3, stride=2),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(32, 16, 3, stride=2),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(16, 8, 3, stride=2),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(8, 4, 4, stride=2),\n",
        "            nn.ReLU(True),\n",
        "        )\n",
        "\n",
        "        self.shared_decoder_expand = nn.Sequential(\n",
        "            nn.ConvTranspose3d(4, 4, kernel_size = (1, 1, 3), stride=1),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "        self.v = nn.Sequential(nn.Linear(512, 100), nn.ReLU(), nn.Linear(100, 1))\n",
        "        self.fc = nn.Sequential(nn.Linear(512, 100), nn.ReLU())\n",
        "        self.alpha_head = nn.Sequential(nn.Linear(100, 3), nn.Softplus())\n",
        "        self.beta_head = nn.Sequential(nn.Linear(100, 3), nn.Softplus())\n",
        "        self.apply(self._weights_init)\n",
        "\n",
        "    def forward(self, input, get_v = False, input_type = \"Source\", eta = 0.1):\n",
        "        sketch = self.sketch(input)\n",
        "        sketch = torch.squeeze(sketch)\n",
        "        # Shared\n",
        "        shared_encode = self.shared_encoder(sketch)\n",
        "        shared_encode = shared_encode.view(-1, 48 * 5 * 5)\n",
        "        shared_encode = self.shared_fc(shared_encode)\n",
        "\n",
        "        if (get_v): return self.v(shared_encode)\n",
        "\n",
        "        # Private\n",
        "        if (input_type == \"Source\" or input_type == \"S\"):\n",
        "            private_encode = self.source_encoder(sketch)\n",
        "            private_encode = private_encode.view(-1, 64 * 5 * 5)\n",
        "            private_encode = self.source_fc(private_encode)\n",
        "\n",
        "            v = self.v(shared_encode)\n",
        "            out = self.fc(shared_encode)\n",
        "            alpha = self.alpha_head(out) + 1\n",
        "            beta = self.beta_head(out) + 1\n",
        "        else:\n",
        "            private_encode = self.target_encoder(sketch)\n",
        "            private_encode = private_encode.view(-1, 64 * 5 * 5)\n",
        "            private_encode = self.target_fc(private_encode)\n",
        "\n",
        "        # Domain\n",
        "        reversed_shared_code = ReverseLayerF.apply(shared_encode, eta)\n",
        "        domain_label = self.pred_domain(reversed_shared_code)\n",
        "\n",
        "        # Decoder\n",
        "        rec_vec = self.shared_decoder_fc(private_encode + shared_encode)\n",
        "        rec_vec = rec_vec.view(-1, 64, 5, 5)\n",
        "        rec_code = self.shared_decoder_conv(rec_vec)\n",
        "        rec_code = rec_code.unsqueeze(-1)\n",
        "        rec_code = self.shared_decoder_expand(rec_code)\n",
        "\n",
        "        if (input_type == \"Source\" or input_type == \"S\"):\n",
        "            return (alpha, beta), v, domain_label, rec_code, shared_encode, private_encode\n",
        "        else:\n",
        "            return domain_label, rec_code, shared_encode, private_encode\n",
        "\n",
        "    @staticmethod\n",
        "    def _weights_init(m):\n",
        "        if isinstance(m, nn.Conv2d):\n",
        "            nn.init.xavier_uniform_(m.weight, gain=nn.init.calculate_gain('relu'))\n",
        "            nn.init.constant_(m.bias, 0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loss Functions"
      ],
      "metadata": {
        "id": "Sx66s0bPkHl2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MSE(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MSE, self).__init__()\n",
        "\n",
        "    def forward(self, pred, real):\n",
        "        diffs = torch.add(real, -pred)\n",
        "        n = torch.numel(diffs.data)\n",
        "        mse = torch.sum(diffs.pow(2)) / n\n",
        "\n",
        "        return mse\n",
        "\n",
        "\n",
        "class SIMSE(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(SIMSE, self).__init__()\n",
        "\n",
        "    def forward(self, pred, real):\n",
        "        diffs = torch.add(real, - pred)\n",
        "        n = torch.numel(diffs.data)\n",
        "        simse = torch.sum(diffs).pow(2) / (n ** 2)\n",
        "\n",
        "        return simse\n",
        "\n",
        "\n",
        "class DiffLoss(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(DiffLoss, self).__init__()\n",
        "\n",
        "    def forward(self, input1, input2):\n",
        "\n",
        "        batch_size = input1.size(0)\n",
        "        input1 = input1.view(batch_size, -1)\n",
        "        input2 = input2.view(batch_size, -1)\n",
        "\n",
        "        input1_l2_norm = torch.norm(input1, p=2, dim=1, keepdim=True).detach()\n",
        "        input1_l2 = input1.div(input1_l2_norm.expand_as(input1) + 1e-6)\n",
        "\n",
        "        input2_l2_norm = torch.norm(input2, p=2, dim=1, keepdim=True).detach()\n",
        "        input2_l2 = input2.div(input2_l2_norm.expand_as(input2) + 1e-6)\n",
        "\n",
        "        diff_loss = torch.mean((input1_l2.t().mm(input2_l2)).pow(2))\n",
        "\n",
        "        return diff_loss"
      ],
      "metadata": {
        "id": "1CyEmCTSNYI2"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_classification = torch.nn.CrossEntropyLoss().cuda()\n",
        "loss_recon1 = MSE()\n",
        "loss_recon2 = SIMSE()\n",
        "loss_diff = DiffLoss()\n",
        "loss_similarity = torch.nn.CrossEntropyLoss().cuda()"
      ],
      "metadata": {
        "id": "QI-AjVukNCG5"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Agent"
      ],
      "metadata": {
        "id": "ZXct1Z4bkKPX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Agent():\n",
        "    max_grad_norm = 0.5\n",
        "    clip_param = 0.1\n",
        "    ppo_epoch = 10\n",
        "    alpha_weight = 0.01\n",
        "    beta_weight = 0.075\n",
        "    gamma_weight = 0.5\n",
        "\n",
        "    transition = np.dtype([('s', np.float64, (4, 96, 96, 3)), ('a', np.float64, (3,)), ('a_logp', np.float64),\n",
        "                            ('r', np.float64), ('s_', np.float64, (4, 96, 96, 3))])\n",
        "    \n",
        "    def __init__(self, net, criterion, optimizer, buffer_capacity = 2048, batch_size = 128):\n",
        "        self.net = net\n",
        "        self.buffer_capacity = buffer_capacity\n",
        "        self.batch_size = batch_size\n",
        "        self.criterion = criterion\n",
        "        self.optimizer = optimizer\n",
        "\n",
        "        self.source_buffer = np.empty(self.buffer_capacity, dtype=self.transition)\n",
        "        self.counter = 0\n",
        "\n",
        "    def select_action(self, state):\n",
        "        state = torch.from_numpy(state).double().to(device).unsqueeze(0)\n",
        "        with torch.no_grad():\n",
        "            alpha, beta = self.net(state)[0]\n",
        "\n",
        "        dist = Beta(alpha, beta)\n",
        "        action = dist.sample()\n",
        "        a_logp = dist.log_prob(action).sum(dim=1)\n",
        "\n",
        "        action = action.squeeze().cpu().numpy()\n",
        "        a_logp = a_logp.item()\n",
        "        return action, a_logp\n",
        "\n",
        "    def store(self, transition):\n",
        "        self.source_buffer[self.counter] = transition\n",
        "        self.counter += 1\n",
        "        if self.counter == self.buffer_capacity:\n",
        "            self.counter = 0\n",
        "            return True\n",
        "\n",
        "        return False\n",
        "\n",
        "    def get_batch(self):\n",
        "        return self.source_buffer\n",
        "\n",
        "    def update(self, epoch, eta = 0.1):\n",
        "        s = torch.tensor(self.source_buffer['s'], dtype=torch.double).to(device)\n",
        "        a = torch.tensor(self.source_buffer['a'], dtype=torch.double).to(device)\n",
        "        r = torch.tensor(self.source_buffer['r'], dtype=torch.double).to(device).view(-1, 1)\n",
        "        s_ = torch.tensor(self.source_buffer['s_'], dtype=torch.double).to(device)\n",
        "        old_a_logp = torch.tensor(self.source_buffer['a_logp'], dtype=torch.double).to(device).view(-1, 1)\n",
        "\n",
        "        source_domain_label = torch.zeros(self.batch_size).long()\n",
        "        target_domain_label = torch.ones(self.batch_size).long()\n",
        "        source_domain_label = source_domain_label.to(device)\n",
        "        target_domain_label = target_domain_label.to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            target_v = r + 0.99 * self.net(s_, get_v = True)\n",
        "            adv = target_v - self.net(s, get_v = True)\n",
        "\n",
        "        image_array = []\n",
        "        source_acc_array, target_acc_array = [], []\n",
        "        s_loss, t_loss = [0, 0], [0, 0]\n",
        "        for _ in range(self.ppo_epoch):\n",
        "            total = 0\n",
        "            source_domain_correct, target_domain_correct = 0, 0\n",
        "            add_image = True\n",
        "            for index in BatchSampler(SubsetRandomSampler(range(self.buffer_capacity)), self.batch_size, True):\n",
        "                total += self.batch_size\n",
        "                # Source\n",
        "                (alpha, beta), v, domain_label, rec_code_s, shared_encode, private_encode = self.net(s[index], eta = eta)\n",
        "                _, predicted = torch.max(domain_label.data, 1)\n",
        "                source_domain_correct += predicted.eq(source_domain_label.data).cpu().sum().item()\n",
        "\n",
        "                # PPO update\n",
        "                dist = Beta(alpha, beta)\n",
        "                a_logp = dist.log_prob(a[index]).sum(dim=1, keepdim=True)\n",
        "                ratio = torch.exp(a_logp - old_a_logp[index])\n",
        "                surr1 = ratio * adv[index]\n",
        "                surr2 = torch.clamp(ratio, 1.0 - self.clip_param, 1.0 + self.clip_param) * adv[index]\n",
        "\n",
        "                # Loss\n",
        "                similarity_loss = self.gamma_weight * loss_similarity(domain_label, source_domain_label)\n",
        "                recon_loss_1 = self.alpha_weight * loss_recon1(rec_code_s, s[index])\n",
        "                recon_loss_2 = self.alpha_weight * loss_recon2(rec_code_s, s[index])\n",
        "                action_loss = -torch.min(surr1, surr2).mean()\n",
        "                value_loss = F.smooth_l1_loss(v, target_v[index])\n",
        "\n",
        "                loss = action_loss + 2. * value_loss + similarity_loss + recon_loss_1 + recon_loss_2\n",
        "                self.net.zero_grad()\n",
        "                loss.backward()\n",
        "                self.optimizer.step()\n",
        "\n",
        "                s_loss[0] += recon_loss_1.cpu().detach().numpy()\n",
        "                s_loss[1] += recon_loss_2.cpu().detach().numpy()\n",
        "\n",
        "                # Target\n",
        "                with torch.no_grad():\n",
        "                    target_batch = get_random_buffer(s[index], self.batch_size)\n",
        "\n",
        "                domain_label, rec_code_t, shared_encode, private_encode = self.net(target_batch, input_type = \"Target\", eta = eta)\n",
        "                _, predicted = torch.max(domain_label.data, 1)\n",
        "                target_domain_correct += predicted.eq(target_domain_label.data).cpu().sum().item()\n",
        "                # Loss\n",
        "                similarity_loss = self.gamma_weight * loss_similarity(domain_label, target_domain_label)\n",
        "                recon_loss_1 = self.alpha_weight * loss_recon1(rec_code_t, s[index])\n",
        "                recon_loss_2 = self.alpha_weight * loss_recon2(rec_code_t, s[index])\n",
        "\n",
        "\n",
        "                loss = similarity_loss + recon_loss_1 + recon_loss_2\n",
        "                self.net.zero_grad()\n",
        "                loss.backward()\n",
        "                self.optimizer.step()\n",
        "\n",
        "                t_loss[0] += recon_loss_1.cpu().detach().numpy()\n",
        "                t_loss[1] += recon_loss_2.cpu().detach().numpy()\n",
        "\n",
        "                if (add_image):\n",
        "                    image = s[index][0][0].reshape(96, 96, 3)\n",
        "                    image = (image + 1) / 2\n",
        "                    image = image.cpu().detach().numpy()\n",
        "                    image_array.append(image)\n",
        "                \n",
        "                    image = target_batch[0][0].reshape(96, 96, 3)\n",
        "                    image = (image + 1) / 2\n",
        "                    image = image.cpu().detach().numpy()\n",
        "                    image_array.append(image)\n",
        "\n",
        "                    image = rec_code_s[0][0].reshape(96, 96, 3)\n",
        "                    image = (image + 1) / 2\n",
        "                    image = image.cpu().detach().numpy()\n",
        "                    image_array.append(image)\n",
        "                \n",
        "                    image = rec_code_t[0][0].reshape(96, 96, 3)\n",
        "                    image = (image + 1) / 2\n",
        "                    image = image.cpu().detach().numpy()\n",
        "                    image_array.append(image)\n",
        "                    \n",
        "                    add_image = False\n",
        "\n",
        "            source_acc_array.append( source_domain_correct / total )\n",
        "            target_acc_array.append( target_domain_correct / total )\n",
        "\n",
        "        source_acc_mean, target_acc_mean = 0, 0\n",
        "        for acc in source_acc_array: source_acc_mean += acc\n",
        "        for acc in target_acc_array: target_acc_mean += acc\n",
        "            \n",
        "        f, axs = plt.subplots(10, 4, figsize = (16, 30))\n",
        "        for j in range (0, 10):\n",
        "            for i in range (0, 4):\n",
        "              if (i == 0): axs[j][i].set_title(\"Source\")\n",
        "              elif (i == 1): axs[j][i].set_title(\"Target\")\n",
        "              elif (i == 2): axs[j][i].set_title(\"Source Recon\")\n",
        "              elif (i == 3): axs[j][i].set_title(\"Target Recon\")\n",
        "        axs = axs.flatten()\n",
        "        for img, ax in zip(image_array, axs):\n",
        "            ax.imshow(img)\n",
        "        f.savefig('./output_r/Recon_image_%04d.png' % epoch)\n",
        "        plt.close(f)\n",
        "        \n",
        "        return source_acc_mean / 10 , target_acc_mean / 10, s_loss, t_loss"
      ],
      "metadata": {
        "id": "n5cceWCtXDy0"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Agent Trainig"
      ],
      "metadata": {
        "id": "PDML5gaIkeYn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def eval(agent, env):\n",
        "    score = 0\n",
        "    state = env.reset()\n",
        "\n",
        "    for t in range(1000):\n",
        "        action, a_logp = agent.select_action(state)\n",
        "\n",
        "        state_, reward, done, _ = env.step_eval(action * np.array([2., 1., 1.]) + np.array([-1., 0., 0.]))\n",
        "\n",
        "        score += reward\n",
        "\n",
        "        state = state_\n",
        "\n",
        "        if done:\n",
        "            break\n",
        "\n",
        "    return score"
      ],
      "metadata": {
        "id": "5nbd6qsQkP51"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(source_env, target_env, agent):\n",
        "    training_records= []\n",
        "    running_score_records = []\n",
        "    running_score = 0\n",
        "    \n",
        "    s_running_score = 0\n",
        "    s_training_records = []\n",
        "    s_running_score_records = []\n",
        "    c1_running_score, c2_running_score = 0, 0\n",
        "    c1_training_records, c2_training_records = [], []\n",
        "    c1_running_score_records, c2_running_score_records = [], []\n",
        "\n",
        "    s_acc_lst, t_acc_lst = [], []\n",
        "    s_recon_loss_1_lst, t_recon_loss_1_lst = [], []\n",
        "    s_recon_loss_2_lst, t_recon_loss_2_lst = [], []\n",
        "\n",
        "    eta = 0.1\n",
        "    for i_ep in range(3000):\n",
        "        score = 0\n",
        "        state = source_env.reset()\n",
        "\n",
        "        for t in range(1000):\n",
        "            action, a_logp = agent.select_action(state)\n",
        "            state_, reward, done, die = source_env.step(action * np.array([2., 1., 1.])\\\n",
        "                                                              + np.array([-1., 0., 0.]))\n",
        "            score += reward\n",
        "\n",
        "            should_update = agent.store((state, action, a_logp, reward, state_))\n",
        "\n",
        "            if should_update: \n",
        "                if (i_ep < 500): eta_max =  1.0\n",
        "                elif (i_ep < 1500): eta_max = 0.9\n",
        "                else: eta_max = 0.7\n",
        "                    \n",
        "                print(\"eta: %.2f\" % eta)\n",
        "                s_acc, t_acc, s_loss, t_loss = agent.update(epoch = i_ep, eta = eta) \n",
        "                s_acc_lst.append(s_acc)\n",
        "                t_acc_lst.append(t_acc)\n",
        "                s_recon_loss_1_lst.append(s_loss[0])\n",
        "                t_recon_loss_1_lst.append(t_loss[0])\n",
        "                s_recon_loss_2_lst.append(s_loss[1])\n",
        "                t_recon_loss_2_lst.append(t_loss[1])\n",
        "\n",
        "                f, axs = plt.subplots(3, 1, figsize = (18, 8))\n",
        "                axs[0].plot(range(len(s_acc_lst)), s_acc_lst)\n",
        "                axs[0].plot(range(len(t_acc_lst)), t_acc_lst)\n",
        "                axs[0].legend(['Source', 'Target'])\n",
        "                axs[0].set_title(\"Domain Acc\")\n",
        "\n",
        "                axs[1].plot(range(len(s_recon_loss_1_lst)), s_recon_loss_1_lst)\n",
        "                axs[1].plot(range(len(t_recon_loss_1_lst)), t_recon_loss_1_lst)\n",
        "                axs[1].legend(['Source', 'Target'])\n",
        "                axs[1].set_title(\"Recon 1\")\n",
        "\n",
        "                axs[2].plot(range(len(s_recon_loss_2_lst)), s_recon_loss_2_lst)\n",
        "                axs[2].plot(range(len(t_recon_loss_2_lst)), t_recon_loss_2_lst)\n",
        "                axs[2].legend(['Source', 'Target'])\n",
        "                axs[2].set_title(\"Recon 2\")\n",
        "\n",
        "                f.savefig('./output_r/loss_%04d.png' % i_ep)\n",
        "                plt.close(f)\n",
        "                \n",
        "            state = state_\n",
        "\n",
        "            if done or die: break\n",
        "                \n",
        "        training_records.append(score)\n",
        "        running_score = running_score * 0.99 + score * 0.01\n",
        "        running_score_records.append(running_score)\n",
        "        \n",
        "        s_score = eval(agent, source_env)\n",
        "        c1_score = eval(agent, target_env[0])\n",
        "        c2_score = eval(agent, target_env[1])\n",
        "\n",
        "        s_training_records.append(s_score)\n",
        "        c1_training_records.append(c1_score)\n",
        "        c2_training_records.append(c2_score)\n",
        "        \n",
        "        s_running_score = s_running_score * 0.99 + s_score * 0.01\n",
        "        c1_running_score = c1_running_score * 0.99 + c1_score * 0.01\n",
        "        c2_running_score = c2_running_score * 0.99 + c2_score * 0.01\n",
        "\n",
        "        s_running_score_records.append(s_running_score)\n",
        "        c1_running_score_records.append(c1_running_score)\n",
        "        c2_running_score_records.append(c2_running_score)\n",
        "        \n",
        "        if (i_ep % 20 == 0):\n",
        "            print('Ep {}\\tLast score: {:.2f}\\tMoving average score: {:.2f}'.format(i_ep, score, running_score))\n",
        "            print('c1 score: {:.2f}\\t c1 Moving average: {:.2f}'.format(c1_score, c1_running_score))\n",
        "            print('c2 score: {:.2f}\\t c2 Moving average: {:.2f}'.format(c2_score, c2_running_score))\n",
        "            \n",
        "            if (i_ep != 0):\n",
        "                f, axs = plt.subplots(1, 2, figsize = (16, 8))\n",
        "                axs[0].plot(range(len(s_training_records)), s_training_records)\n",
        "                axs[1].plot(range(len(s_running_score_records)), s_running_score_records)\n",
        "                axs[0].plot(range(len(c1_training_records)), c1_training_records)\n",
        "                axs[1].plot(range(len(c1_running_score_records)), c1_running_score_records)\n",
        "                axs[0].plot(range(len(c2_training_records)), c2_training_records)\n",
        "                axs[1].plot(range(len(c2_running_score_records)), c2_running_score_records)\n",
        "\n",
        "                axs[0].legend(['Source', 'Env c1', 'Env c2'])\n",
        "                axs[0].set_title(\"Scores\")\n",
        "                axs[1].legend(['Source', 'Env c1', 'Env c2'])\n",
        "                axs[1].set_title(\"Average Score\")\n",
        "\n",
        "                f.savefig('./output_r/scores_%04d.png' % i_ep)\n",
        "                plt.close(f)"
      ],
      "metadata": {
        "id": "dG8TknrYkXG2"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "green_env = Env(color = 'g', seed = 0)\n",
        "env_c1 = Env(color = 'c1', seed = 0)\n",
        "env_c2 = Env(color = 'c2', seed = 0)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss().cuda()\n",
        "net = DSN().double().cuda()\n",
        "optimizer = optim.Adam(net.parameters(), lr=1e-3)\n",
        "agent = Agent(net = net,  criterion = criterion,  optimizer = optimizer, buffer_capacity = 2048, batch_size = 128)\n",
        "\n",
        "source_env = green_env\n",
        "target_env = [env_c1, env_c2]\n",
        "train(green_env, target_env, agent)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hyCpJ2RhkaX1",
        "outputId": "38ce0472-0c5a-4472-ffd9-c27c787f0f46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gym/spaces/box.py:74: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
            "  \"Box bound precision lowered by casting to {}\".format(self.dtype)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 0\tLast score: -21.62\tMoving average score: -0.22\n",
            "c1 score: -22.82\t c1 Moving average: -0.23\n",
            "c2 score: -19.46\t c2 Moving average: -0.19\n",
            "retry to generate track (normal if there are not manyinstances of this message)\n",
            "retry to generate track (normal if there are not manyinstances of this message)\n",
            "retry to generate track (normal if there are not manyinstances of this message)\n",
            "retry to generate track (normal if there are not manyinstances of this message)\n",
            "eta: 0.10\n",
            "retry to generate track (normal if there are not manyinstances of this message)\n",
            "retry to generate track (normal if there are not manyinstances of this message)\n",
            "retry to generate track (normal if there are not manyinstances of this message)\n",
            "Ep 20\tLast score: -18.05\tMoving average score: -3.49\n",
            "c1 score: -32.26\t c1 Moving average: -4.78\n",
            "c2 score: -32.26\t c2 Moving average: -4.75\n",
            "retry to generate track (normal if there are not manyinstances of this message)\n",
            "retry to generate track (normal if there are not manyinstances of this message)\n",
            "retry to generate track (normal if there are not manyinstances of this message)\n",
            "retry to generate track (normal if there are not manyinstances of this message)\n",
            "eta: 0.10\n",
            "retry to generate track (normal if there are not manyinstances of this message)\n",
            "retry to generate track (normal if there are not manyinstances of this message)\n",
            "retry to generate track (normal if there are not manyinstances of this message)\n",
            "retry to generate track (normal if there are not manyinstances of this message)\n",
            "retry to generate track (normal if there are not manyinstances of this message)\n",
            "Ep 40\tLast score: -21.24\tMoving average score: -6.43\n",
            "c1 score: -38.65\t c1 Moving average: -8.75\n",
            "c2 score: -38.65\t c2 Moving average: -8.76\n",
            "retry to generate track (normal if there are not manyinstances of this message)\n",
            "retry to generate track (normal if there are not manyinstances of this message)\n",
            "retry to generate track (normal if there are not manyinstances of this message)\n",
            "retry to generate track (normal if there are not manyinstances of this message)\n",
            "retry to generate track (normal if there are not manyinstances of this message)\n",
            "retry to generate track (normal if there are not manyinstances of this message)\n",
            "eta: 0.10\n",
            "retry to generate track (normal if there are not manyinstances of this message)\n",
            "retry to generate track (normal if there are not manyinstances of this message)\n",
            "retry to generate track (normal if there are not manyinstances of this message)\n",
            "retry to generate track (normal if there are not manyinstances of this message)\n",
            "retry to generate track (normal if there are not manyinstances of this message)\n",
            "Ep 60\tLast score: -17.98\tMoving average score: -8.10\n",
            "c1 score: -1.57\t c1 Moving average: -11.89\n",
            "c2 score: -5.51\t c2 Moving average: -11.99\n",
            "retry to generate track (normal if there are not manyinstances of this message)\n",
            "retry to generate track (normal if there are not manyinstances of this message)\n",
            "retry to generate track (normal if there are not manyinstances of this message)\n",
            "eta: 0.10\n",
            "retry to generate track (normal if there are not manyinstances of this message)\n",
            "retry to generate track (normal if there are not manyinstances of this message)\n",
            "retry to generate track (normal if there are not manyinstances of this message)\n",
            "retry to generate track (normal if there are not manyinstances of this message)\n",
            "retry to generate track (normal if there are not manyinstances of this message)\n",
            "retry to generate track (normal if there are not manyinstances of this message)\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.10.6 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.6"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
      }
    },
    "colab": {
      "provenance": [],
      "name": "“dsn.ipynb”的副本",
      "collapsed_sections": [
        "sXw-vOXxju2p",
        "w676toodj6G1",
        "Sx66s0bPkHl2"
      ],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}